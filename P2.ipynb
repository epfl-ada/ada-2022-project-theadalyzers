{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5933ab57",
   "metadata": {},
   "source": [
    "# Hyperlinks' clickability preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9f0b041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.parse\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd6a6e28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r/Royal_Marines.htm',\n",
       " 'r/Recycling.htm',\n",
       " 'r/Retreat_of_glaciers_since_1850.htm',\n",
       " 'r/Remember_Girls_Like_Rajpura.htm',\n",
       " 'r/Rutherfordium.htm',\n",
       " 'r/Rule_of_St_Benedict.htm',\n",
       " 'r/Red_dwarf.htm',\n",
       " 'r/Romeo_and_Juliet.htm',\n",
       " 'r/Rudyard_Kipling.htm',\n",
       " 'r/Race.htm']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# HTLM files URLs in a list \n",
    "wp_path = \"/Users/ginevralarroux/Desktop/EPFL courses/Applied data analysis/ADA project/data/wpcd/wp/\" # to adapt\n",
    "directories = os.listdir(wp_path)\n",
    "html_list = []\n",
    "for dir in directories:\n",
    "    local_path = wp_path + dir\n",
    "    local_dir = os.listdir(local_path)\n",
    "    for link in local_dir:\n",
    "        if link[-3:]=='htm':\n",
    "            html_list.append(dir+'/'+link)\n",
    "html_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4abdba1",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The aim of this specific section of our game strategy analysis is to test whether Wikispeedia players have clikability preferences on the basis of the hyperlinks' positioning throughout the article text. \n",
    "In particular:\n",
    "1. we wil find the ordinal number of the paragraph each hyperlink in an article shows up in and divide it by the total number of paragraphs of the article, to determine its positioning; \n",
    "2. we will determine if each hyperlink in an article shows up in an image caption.\n",
    "\n",
    "We will then investigate if there is a correlation between the clickability of the hyperlinks and their location, using the proper statistical tests. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05bb6ef",
   "metadata": {},
   "source": [
    "### Hyperlinks positioning in articles' text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367618fb",
   "metadata": {},
   "source": [
    "It is essential to extract from the data the frequency of clicks for each hyperlink."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb1a99ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files \n",
    "folder='/Users/ginevralarroux/Desktop/EPFL courses/Applied data analysis/ADA project/data/wikispeedia_paths-and-graph/'\n",
    "\n",
    "paths_finished='paths_finished.tsv'\n",
    "paths_unfinished='paths_unfinished.tsv'\n",
    "articles='articles.tsv'\n",
    "\n",
    "paths_finished=pd.read_csv(folder+paths_finished, sep='\\t', skiprows=15, header=None, names=['hashedIpAddress', 'timestamp', 'durationInSec', 'path', 'rating'])\n",
    "paths_unfinished=pd.read_csv(folder+paths_unfinished, sep='\\t', skiprows=16, header=None, names=['hashedIpAddress', 'timestamp', 'durationInSec', 'path', 'target', 'type'])\n",
    "articles=pd.read_csv(folder+articles, sep='\\t', skiprows=12, header=None, names=['article'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b35d62",
   "metadata": {},
   "source": [
    "The dataframe `paths_finished` contains the paths chosen by the players who could reach the target article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2e72681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashedIpAddress</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>durationInSec</th>\n",
       "      <th>path</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6a3701d319fc3754</td>\n",
       "      <td>1297740409</td>\n",
       "      <td>166</td>\n",
       "      <td>14th_century;15th_century;16th_century;Pacific...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3824310e536af032</td>\n",
       "      <td>1344753412</td>\n",
       "      <td>88</td>\n",
       "      <td>14th_century;Europe;Africa;Atlantic_slave_trad...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>415612e93584d30e</td>\n",
       "      <td>1349298640</td>\n",
       "      <td>138</td>\n",
       "      <td>14th_century;Niger;Nigeria;British_Empire;Slav...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64dd5cd342e3780c</td>\n",
       "      <td>1265613925</td>\n",
       "      <td>37</td>\n",
       "      <td>14th_century;Renaissance;Ancient_Greece;Greece</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>015245d773376aab</td>\n",
       "      <td>1366730828</td>\n",
       "      <td>175</td>\n",
       "      <td>14th_century;Italy;Roman_Catholic_Church;HIV;R...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hashedIpAddress   timestamp  durationInSec  \\\n",
       "0  6a3701d319fc3754  1297740409            166   \n",
       "1  3824310e536af032  1344753412             88   \n",
       "2  415612e93584d30e  1349298640            138   \n",
       "3  64dd5cd342e3780c  1265613925             37   \n",
       "4  015245d773376aab  1366730828            175   \n",
       "\n",
       "                                                path  rating  \n",
       "0  14th_century;15th_century;16th_century;Pacific...     NaN  \n",
       "1  14th_century;Europe;Africa;Atlantic_slave_trad...     3.0  \n",
       "2  14th_century;Niger;Nigeria;British_Empire;Slav...     NaN  \n",
       "3     14th_century;Renaissance;Ancient_Greece;Greece     NaN  \n",
       "4  14th_century;Italy;Roman_Catholic_Church;HIV;R...     3.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths_finished.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a47b5f",
   "metadata": {},
   "source": [
    "The dataframe `paths_unfinished` contains the paths chosen by the players who could not reach the target article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1279013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashedIpAddress</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>durationInSec</th>\n",
       "      <th>path</th>\n",
       "      <th>target</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2426091a53125110</td>\n",
       "      <td>1297054935</td>\n",
       "      <td>1804</td>\n",
       "      <td>Obi-Wan_Kenobi</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>timeout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26141fd878806294</td>\n",
       "      <td>1297055651</td>\n",
       "      <td>1805</td>\n",
       "      <td>Julius_Caesar</td>\n",
       "      <td>Caracas</td>\n",
       "      <td>timeout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2b015fb8181c48f2</td>\n",
       "      <td>1297090819</td>\n",
       "      <td>1818</td>\n",
       "      <td>Malawi;Democracy;Alexander_the_Great</td>\n",
       "      <td>First_Crusade</td>\n",
       "      <td>timeout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53a53bc244e08a6a</td>\n",
       "      <td>1297094761</td>\n",
       "      <td>49</td>\n",
       "      <td>Paraguay</td>\n",
       "      <td>Mount_St._Helens</td>\n",
       "      <td>restart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53a53bc244e08a6a</td>\n",
       "      <td>1297099105</td>\n",
       "      <td>1808</td>\n",
       "      <td>Paraguay;Bolivia</td>\n",
       "      <td>Mount_St._Helens</td>\n",
       "      <td>timeout</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hashedIpAddress   timestamp  durationInSec  \\\n",
       "0  2426091a53125110  1297054935           1804   \n",
       "1  26141fd878806294  1297055651           1805   \n",
       "2  2b015fb8181c48f2  1297090819           1818   \n",
       "3  53a53bc244e08a6a  1297094761             49   \n",
       "4  53a53bc244e08a6a  1297099105           1808   \n",
       "\n",
       "                                   path            target     type  \n",
       "0                        Obi-Wan_Kenobi         Microsoft  timeout  \n",
       "1                         Julius_Caesar           Caracas  timeout  \n",
       "2  Malawi;Democracy;Alexander_the_Great     First_Crusade  timeout  \n",
       "3                              Paraguay  Mount_St._Helens  restart  \n",
       "4                      Paraguay;Bolivia  Mount_St._Helens  timeout  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths_unfinished.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00681d55",
   "metadata": {},
   "source": [
    "The dataframe `articles` lists all the clickable articles/links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8d25afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>áedán mac gabráin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>åland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>édouard manet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>éire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>óengus i of the picts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>€2 commemorative coins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13th century</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  article\n",
       "0       áedán mac gabráin\n",
       "1                   åland\n",
       "2           édouard manet\n",
       "3                    éire\n",
       "4   óengus i of the picts\n",
       "5  €2 commemorative coins\n",
       "6            10th century\n",
       "7            11th century\n",
       "8            12th century\n",
       "9            13th century"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode and filter link names\n",
    "def filter_link(link):\n",
    "    link=urllib.parse.unquote(link)\n",
    "    link=link.lower()\n",
    "    link=link.replace('_', ' ')\n",
    "    link=link.strip()\n",
    "    return link\n",
    "\n",
    "articles.article=articles.article.apply(filter_link)\n",
    "articles.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7948037",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of articles comprising the Wikispeedia library is 4604.\n"
     ]
    }
   ],
   "source": [
    "print('The total number of articles comprising the Wikispeedia library is {0}.'.format(len(articles)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4873d8f9",
   "metadata": {},
   "source": [
    "The dataframe `clicked_links_filtered` contains the clicked links troughout the paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "779b00fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['14th century',\n",
       "  '15th century',\n",
       "  '16th century',\n",
       "  'pacific ocean',\n",
       "  'atlantic ocean',\n",
       "  'accra',\n",
       "  'africa',\n",
       "  'atlantic slave trade',\n",
       "  'african slave trade'],\n",
       " ['14th century',\n",
       "  'europe',\n",
       "  'africa',\n",
       "  'atlantic slave trade',\n",
       "  'african slave trade'],\n",
       " ['14th century',\n",
       "  'niger',\n",
       "  'nigeria',\n",
       "  'british empire',\n",
       "  'slavery',\n",
       "  'africa',\n",
       "  'atlantic slave trade',\n",
       "  'african slave trade'],\n",
       " ['14th century', 'renaissance', 'ancient greece', 'greece'],\n",
       " ['14th century',\n",
       "  'italy',\n",
       "  'roman catholic church',\n",
       "  'hiv',\n",
       "  'ronald reagan',\n",
       "  'president of the united states',\n",
       "  'john f. kennedy']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_clicked_links(paths_df):\n",
    "    clicked_links=[]\n",
    "    removed_idxs=[]\n",
    "    for idx, path in enumerate(paths_df['path']): \n",
    "        links_list=(path.split(';'))# get list of links along the path string \n",
    "        links_list_uncoded=[filter_link(link) for link in links_list]\n",
    "        if (len(links_list_uncoded)) <= 1 or ('<' in links_list_uncoded):\n",
    "            removed_idxs.append(idx)\n",
    "            continue\n",
    "        else:\n",
    "            clicked_links.append(links_list_uncoded)\n",
    "    return clicked_links, removed_idxs\n",
    "\n",
    "clicked_links_filtered_f, removed_f=get_clicked_links(paths_finished) #f for paths_finished\n",
    "clicked_links_filtered_u, removed_u=get_clicked_links(paths_unfinished) #u for paths_unfinished\n",
    "clicked_links_filtered_f[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "157162c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W.r.t the succesfull players dataframe, a total number of 42312 paths are kept, out of 51318: 9006 were discarded.\n"
     ]
    }
   ],
   "source": [
    "print('W.r.t the succesfull players dataframe, a total number of {0} paths are kept, out of {1}: {2} were discarded.'.format(len(clicked_links_filtered_f), len(removed_f)+len(clicked_links_filtered_f), len(removed_f))) \n",
    "##need to comment why do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb1aab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W.r.t the unsuccesfull players dataframe, a total number of 14460 paths are kept, out of 24875: 10415 were discarded.\n"
     ]
    }
   ],
   "source": [
    "print('W.r.t the unsuccesfull players dataframe, a total number of {0} paths are kept, out of {1}: {2} were discarded.'.format(len(clicked_links_filtered_u),len(clicked_links_filtered_u)+len(removed_u),\\\n",
    "                                                                                                                               len(removed_u)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831f4d7",
   "metadata": {},
   "source": [
    "The dataframe `links_freq_df` contains the links' frequency of clicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fdf6dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>#_clicks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>åland</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>édouard manet</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>éire</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>€2 commemorative coins</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10th century</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     link  #_clicks\n",
       "1                   åland         1\n",
       "2           édouard manet         1\n",
       "3                    éire         1\n",
       "5  €2 commemorative coins         1\n",
       "6            10th century        66"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_clicks_frequency(paths_list):\n",
    "    \n",
    "    links_name=[]\n",
    "    links_freq=[]\n",
    "\n",
    "    for article in articles['article']: # count the number of times each article shows up in paths\n",
    "        count=0\n",
    "        links_name.append(article)\n",
    "        for path in range(len(paths_list)):\n",
    "            if article in paths_list[path]:\n",
    "                count+=paths_list[path].count(article)\n",
    "        links_freq.append(count)\n",
    "\n",
    "    links_freq_df=pd.concat([pd.Series(links_name), pd.Series(links_freq)], axis=1)\n",
    "    links_freq_df.columns=['link', '#_clicks']\n",
    "    return links_freq_df\n",
    "\n",
    "links_freq_df_f=get_clicks_frequency(clicked_links_filtered_f)\n",
    "links_freq_df_u=get_clicks_frequency(clicked_links_filtered_u)\n",
    "\n",
    "links_freq_df_f.loc[links_freq_df_f['#_clicks']!=0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c1a566b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of clicked hyperlinks by succesfull players is 242257.\n",
      "The total number of clicked hyperlinks by unsuccesfull players is 68711.\n"
     ]
    }
   ],
   "source": [
    "clicks_tot_f=links_freq_df_f['#_clicks'].sum()\n",
    "clicks_tot_u=links_freq_df_u['#_clicks'].sum()\n",
    "print('The total number of clicked hyperlinks by succesfull players is {0}.'.format(clicks_tot_f))\n",
    "print('The total number of clicked hyperlinks by unsuccesfull players is {0}.'.format(clicks_tot_u))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf2121",
   "metadata": {},
   "source": [
    "Next step of the descriptive analysis process is the html files parsing aimed at determining the location of hyperlinks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aae5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse html files \n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soups=[]\n",
    "failed_html_list = []\n",
    "for html in html_list[:]:\n",
    "    f=open(wp_path+html, 'r')\n",
    "    try:\n",
    "        soup = BeautifulSoup(f, 'lxml')\n",
    "        soups.append(soup)\n",
    "    except Exception:\n",
    "        failed_html_list.append(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a9a7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{0} files were not parsable. However, they are not reachable nor it is possible to click \\\n",
    "any hyperlink in those html pages.'.format(len(failed_html_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9df4d68",
   "metadata": {},
   "source": [
    "`link_positioning_dfs` is a list of dataframes (`link_positioning_df`) containing hyperlinks showing up in one html file, the ordinal number of the paragraph they belong to and their relative positioning throughout the article text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aafde19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML tag for hyperlinks is <a href= >\n",
    "# the function finds all <a href= > tags throughout the article html file\n",
    "\n",
    "def find_links(soup): \n",
    "    paragraphs = soup.find_all('p') \n",
    "    links=[]\n",
    "    i=0\n",
    "    for p in paragraphs:\n",
    "        i+=1\n",
    "        all_links=p.find_all('a')\n",
    "        for link in all_links:\n",
    "            if 'href' in link.attrs:\n",
    "                link_title=link.text\n",
    "                link_paragraph=i\n",
    "                links.append([link_title, link_paragraph])\n",
    "                \n",
    "    link_positioning_df=pd.DataFrame(links, columns=['link', '#_paragraph']).drop_duplicates()\n",
    "    link_positioning_df['positioning']=round(link_positioning_df['#_paragraph']/len(paragraphs), 2)\n",
    "    link_positioning_df['link']=link_positioning_df['link'].apply(filter_link)\n",
    "    return link_positioning_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77510d8e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# apply the function to all html files\n",
    "\n",
    "link_positioning_dfs=[]\n",
    "for soup in soups:\n",
    "    link_positioning_dfs.append(find_links(soup))\n",
    "\n",
    "link_positioning_dfs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b16645",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{0} html files were parsed.'.format(len(link_positioning_dfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aecdb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example with 2 files\n",
    "\n",
    "URL_1 = wp_path+'a/A_cappella.htm'\n",
    "URL_2 = wp_path+'m/Music.htm'\n",
    "\n",
    "f1=open(URL_1, 'r')\n",
    "soup1 = BeautifulSoup(f1, 'lxml')\n",
    "\n",
    "f2=open(URL_2, 'r')\n",
    "soup2 = BeautifulSoup(f2, 'lxml')\n",
    "\n",
    "link_positioning_df_1=find_links(soup1).drop(labels='#_paragraph', axis=1)\n",
    "link_positioning_df_2=find_links(soup2).drop(labels='#_paragraph', axis=1)\n",
    "\n",
    "# merging the 2 dataframes \n",
    "\n",
    "merged_dfs=link_positioning_df_1.merge(link_positioning_df_2, how='outer', left_on='link', right_on='link', )\n",
    "merged_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd59259",
   "metadata": {},
   "source": [
    "The hyperlink _rap_ shows up in both articles; the hyperlink _jazz_, _renaissance_ and _time_ show up multiple times in one article. \n",
    "\n",
    "The two occurrences highlighted are likely to be the case for every hyperlink, when all dataframes will be merged. It is therefore essential to compute their most likely positioning in the articles' texts, so to extract any meaningful information from the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c4b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all the link_positioning_df in link_positioning_dfs list on hyperlink in order to apply a function \n",
    "# that determines the most frequent positioning of the hyperlinks\n",
    "\n",
    "link_positioning_dfs_grouped=[]\n",
    "\n",
    "fail=0  \n",
    "for i, df in enumerate(link_positioning_dfs):\n",
    "    try:\n",
    "        df=df.set_index(\"link\")\n",
    "        df=df[\"positioning\"].groupby(\"link\").apply(lambda x: x.values).rename(f\"article_{i}\")\n",
    "        link_positioning_dfs_grouped.append(df)\n",
    "    except:\n",
    "        fail+=1\n",
    "        pass \n",
    "\n",
    "from itertools import chain\n",
    "link_positioning_concatenated=(pd.concat(link_positioning_dfs_grouped)\n",
    "                               .groupby(\"link\")\n",
    "                               .apply(lambda x: list(chain(*x.values))))\n",
    "link_positioning_concatenated[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d602ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that determines the most frequent positioning of each hyperlink in the set of all links\n",
    "\n",
    "def find_positioning(array):\n",
    "    bin_labels=['top', 'center-top','center','center-bottom', 'bottom'] # positioning is classified as top, centre-top, center, center-bottom, or bottom of the article\n",
    "    bins=[0, 0.20, 0.40, 0.60, 0.80, 1] \n",
    "    cut_positioning=pd.cut(array, bins, labels=bin_labels, right=True, include_lowest=True)\n",
    "    positioning_frequency=pd.value_counts(cut_positioning) # frequency of the bins\n",
    "    most=positioning_frequency.apply('max') # bin with highest frequency\n",
    "    if len(positioning_frequency[positioning_frequency==most])>1:\n",
    "        return np.random.choice(positioning_frequency[positioning_frequency==most].index.values.astype(str)) #account for same frequency\n",
    "    else:\n",
    "        return positioning_frequency[positioning_frequency==most].index.values.astype(str).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d10bb",
   "metadata": {},
   "source": [
    "The dataframe `most_freq_positioning_df` contains the hyperlinks' most frequent positioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90237f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all html files\n",
    "\n",
    "most_freq_positioning=link_positioning_concatenated.apply(find_positioning)\n",
    "most_freq_positioning_df=pd.DataFrame(most_freq_positioning, columns=['most_freq_positioning'])\n",
    "most_freq_positioning_df.reset_index(inplace=True)\n",
    "most_freq_positioning_df.head()\n",
    "most_freq_positioning_df.to_csv('most_freq_positioning_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c66cf4",
   "metadata": {},
   "source": [
    "The dataframe `links_freq_pos` contains both the hyperlinks' most frequent positioning and their frequency of clicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd7ae70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "links_freq_pos_f=links_freq_df_f.merge(most_freq_positioning_df, how='outer', left_on='link', right_on='link')\n",
    "links_freq_pos_u=links_freq_df_u.merge(most_freq_positioning_df, how='outer', left_on='link', right_on='link')\n",
    "links_freq_pos_f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc328fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In {0} out of {1} cases clicked links by players don\\'t have a most frequent positioning as they do not show up \\\n",
    "in the dataframe containing hyperlinks in HTML pages. They are replaced with random values.'\\\n",
    "      .format((links_freq_pos_f['most_freq_positioning'].isna()).sum(), len(links_freq_pos_f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1335ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In {0} out of {1} cases clicked links by players don\\'t have a most frequent positioning as they do not show up \\\n",
    "in the dataframe containing hyperlinks in HTML pages. They are replaced with random values.'\\\n",
    "      .format((links_freq_pos_u['most_freq_positioning'].isna()).sum(), len(links_freq_pos_u)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81221928",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_freq_pos_f['most_freq_positioning'].\\\n",
    "fillna(np.random.choice(['top', 'center-top','center','center-bottom', 'bottom']),inplace=True)\n",
    "links_freq_pos_u['most_freq_positioning'].\\\n",
    "fillna(np.random.choice(['top', 'center-top','center','center-bottom', 'bottom']),inplace=True)                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88cddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_freq_pos_f.to_csv('links_freq_pos_f.csv')\n",
    "links_freq_pos_u.to_csv('links_freq_pos_u.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbbc8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_freq_pos_f['#_clicks'].fillna(0,inplace=True) #count NaN as 0 frequency\n",
    "links_freq_pos_u['#_clicks'].fillna(0,inplace=True)\n",
    "not_clicked_f=(links_freq_pos_f['#_clicks']==0).sum() #null #_clicks\n",
    "not_clicked_u=(links_freq_pos_u['#_clicks']==0).sum()\n",
    "print('There are {0} links in the articles, {1} never clicked by succesful players.'.format(len(most_freq_positioning_df), not_clicked_f))\n",
    "print('There are {0} links in the articles, {1} never clicked by unsuccesful players.'.format(len(most_freq_positioning_df), not_clicked_u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1c88f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In respectively {0}, {1} cases the number of clicks per link between successful and unsuccesful players is equal, not equal.'\\\n",
    "      .format((links_freq_pos_f['#_clicks']==links_freq_pos_u['#_clicks']).sum(), \n",
    "      (links_freq_pos_f['#_clicks']!=links_freq_pos_u['#_clicks']).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b49cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90b2547",
   "metadata": {},
   "source": [
    "The dataframe `links_freq_pos_grouped_df` groups the hyperlinks click frequency by their positioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88741b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_freq_pos_grouped_f=pd.DataFrame(links_freq_pos_f['#_clicks'].groupby(links_freq_pos_f['most_freq_positioning']).sum())\n",
    "links_freq_pos_grouped_f['#_clicks_norm']=links_freq_pos_grouped_f['#_clicks']/clicks_tot_f #normalization\n",
    "\n",
    "links_freq_pos_grouped_u=pd.DataFrame(links_freq_pos_u['#_clicks'].groupby(links_freq_pos_u['most_freq_positioning']).sum())\n",
    "links_freq_pos_grouped_u['#_clicks_norm']=links_freq_pos_grouped_u['#_clicks']/clicks_tot_u #normalization\n",
    "\n",
    "links_freq_pos_grouped_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b897a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_freq_pos_grouped_u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b28b84",
   "metadata": {},
   "source": [
    "In order to compare the hyperlinks click frequencies with regard to their positioning (i.e. _top_, _center-top_, _center_, _center-bottom_, _bottom_) their absolute values need to be normalized with the bins' frequencies (i.e. the number of times the hypelinks actually show up in the categorical positioning).\n",
    "\n",
    "The dataframe `positioning_freq_df_grouped` contains the frequency of hyperlinks showing up in the Wikispeedia set of articles grouped by their positioning throughout the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5485341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that counts the frequency of a link showing up at the top, center, bottom of the article\n",
    "\n",
    "def find_positioning_dis(array):\n",
    "    bin_labels=['top', 'center-top','center', 'center-bottom', 'bottom']\n",
    "    bins=[0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "    cut_positioning=pd.cut(array, bins, labels=bin_labels, right=True, include_lowest=True)\n",
    "    positioning_frequency=pd.value_counts(cut_positioning)\n",
    "    return positioning_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b819e3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to the dataframe links positioning grouped by link  \n",
    "\n",
    "positioning_freq=link_positioning_concatenated.apply(find_positioning_dis)\n",
    "positioning_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8604226",
   "metadata": {},
   "outputs": [],
   "source": [
    "positioning_freq_grouped=pd.DataFrame(positioning_freq.sum(axis=0), columns=['nr']) # group by positioning\n",
    "\n",
    "links_tot=positioning_freq_grouped['nr'].sum()\n",
    "positioning_freq_grouped['nr_norm']=positioning_freq_grouped['nr']/links_tot\n",
    "positioning_freq_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f63031e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataframe for visualization\n",
    "\n",
    "vis_f=links_freq_pos_grouped_f.merge(positioning_freq_grouped, left_index=True, right_index=True)\n",
    "vis_u=links_freq_pos_grouped_u.merge(positioning_freq_grouped, left_index=True, right_index=True)\n",
    "vis_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d39ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f6b341",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_f['#_clicks / #_hyperlinks']=vis_f['#_clicks_norm']/vis_f['nr_norm']\n",
    "vis_u['#_clicks / #_hyperlinks']=vis_u['#_clicks_norm']/vis_u['nr_norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7761d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of the distribution of the clicked hyperlinks' positioning\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(16,6))\n",
    "\n",
    "colors=sns.color_palette(\"Set2\")\n",
    "\n",
    "\n",
    "vis_f.plot(y=['#_clicks_norm', 'nr_norm'], kind='bar', ax=ax[0], label=['#_clicks', '#_hyperlinks'], color=colors[1:3], edgecolor='k')\n",
    "ax[0].legend()\n",
    "ax[0].set_title('Distribution of clicks and hyperlinks positioning', fontsize=18)\n",
    "ax[0].set_xlabel('Positioning', fontsize=16)\n",
    "ax[0].set_ylabel('Frequency normalized', fontsize=16)\n",
    "ax[0].set_xticklabels(vis_f.index, rotation=45)\n",
    "\n",
    "vis_f.plot(y='#_clicks / #_hyperlinks', kind='bar', ax=ax[1], label='', color=colors, edgecolor='k')\n",
    "ax[1].legend()\n",
    "ax[1].set_title('Distribution of clickability preference', fontsize=18)\n",
    "ax[1].set_xlabel('Positioning', fontsize=16)\n",
    "ax[1].set_ylabel('#_clicks / #_hyperlinks', fontsize=16)\n",
    "ax[1].set_xticklabels(vis_f.index, rotation=45)\n",
    "\n",
    "fig.savefig('fig_f.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d27e152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b876e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors=sns.color_palette(\"Set2\")\n",
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6671af",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(16,6))\n",
    "\n",
    "colors=sns.color_palette(\"Set2\")\n",
    "\n",
    "vis_u.plot(y=['#_clicks_norm', 'nr_norm'], kind='bar', ax=ax[0], label=['#_clicks', '#_hyperlinks'], color=colors[1:3], edgecolor='k')\n",
    "ax[0].legend()\n",
    "ax[0].set_title('Distribution of clicks and hyperlinks positioning', fontsize=18)\n",
    "ax[0].set_xlabel('Positioning', fontsize=16)\n",
    "ax[0].set_ylabel('Frequency normalized', fontsize=16)\n",
    "ax[0].set_xticklabels(vis_u.index, rotation=45)\n",
    "\n",
    "vis_u.plot(y='#_clicks / #_hyperlinks', kind='bar', ax=ax[1], label='', color=colors, edgecolor='k')\n",
    "ax[1].legend()\n",
    "ax[1].set_title('Distribution of clickability preference', fontsize=18)\n",
    "ax[1].set_xlabel('Positioning', fontsize=16)\n",
    "ax[1].set_ylabel('#_clicks / #_hyperlinks', fontsize=16)\n",
    "ax[1].set_xticklabels(vis_u.index, rotation=45)\n",
    "\n",
    "fig.savefig('fig_u.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93c1aa4",
   "metadata": {},
   "source": [
    "The bar plot on the left illustrates the distribution of the clicked hyperlinks and the total number of links in the articles, on the basis of their positioning throughout the articles text, both normalized. \n",
    "\n",
    "The bar plot on the right illustrates the hyperlinks clickability on the basis of their positioning. More precisely: \n",
    "1. a value of 1 (_\\#_clicks_/_\\#_hyperlinks_ = 1) corresponds to a hyperlinks clickability on average equally proportional to the normalized frequency of the specific categorical positioning (i.e. the number of clicks proportional to the number times a hyperlink shows up in a section of the article);\n",
    "2. a value of greater than 1, points a more than proportional clickability;\n",
    "3. a value of smaller than 1, points a less than proportional clickability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d38d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_f['is_successful']=1\n",
    "vis_u['is_successful']=0\n",
    "vis=pd.concat([vis_f,vis_u], axis=0)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffe8707",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8), sharey=True)\n",
    "\n",
    "sns.barplot(y='#_clicks / #_hyperlinks', x=vis.index, data=vis, palette=sns.color_palette(\"Set2\"), hue='is_successful', edgecolor='k')\n",
    "\n",
    "ax.set_title('Distribution of clickability preference', fontsize=18)\n",
    "ax.set_xlabel('Positioning', fontsize=18)\n",
    "ax.set_ylabel('#_clicks / #_hyperlinks', fontsize=18)\n",
    "ax.legend_.set_title('')\n",
    "labels = ['Unsuccessful', 'Successful']\n",
    "for t, l in zip(ax.legend_.texts, labels):\n",
    "    t.set_text(l)\n",
    "plt.savefig('Distribution_clickability_preference_pos.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63159ba1",
   "metadata": {},
   "source": [
    "There is an evident players' clickability preference for hyperlinks showing up at the top of articles, followed by a preference for bottom and center-bottom positionings. <br>\n",
    "The highest gap between successful and unsuccessful players is for hyperlinks in the center-bottom of articles: successful players click on average more on center-bottom-positioned links than unsuccesful ones. The trend is reversed for top-positioned links. \n",
    "Center-positioned links are clicked the least, both by successful and unsuccessful players. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93379168",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c813f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6c8f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_f.to_csv('vis_f.csv')\n",
    "vis_u.to_csv('vis_u.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0348c5",
   "metadata": {},
   "source": [
    "### Hyperlinks positioning in images' caption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c17b24e",
   "metadata": {},
   "source": [
    "The following part of the descriptive analysis focuses on the location of hyperlinks in images' captions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef79c78",
   "metadata": {},
   "source": [
    "Images in html files can be either found under \\<div> or \\<table> tag, while the hyperlinks are found in their captions under \\<div class='thumbcaption'> tag."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16521bd",
   "metadata": {},
   "source": [
    "The dataframe `links_in_tables` contains the links showing up in tables' captions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3978781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse html file and search hyperlinks in the captions of tables containing images \n",
    "\n",
    "def find_link_in_table(soup):\n",
    "    \n",
    "    tables = soup.find_all('table')\n",
    "\n",
    "    links=[]\n",
    "    for table in tables:\n",
    "        if table.find('img'):\n",
    "            all_links=table.find_all('a')\n",
    "            for link in all_links:\n",
    "                if 'class' not in link.attrs:\n",
    "                    link_title=link.text\n",
    "                    links.append(link_title)\n",
    "\n",
    "    if links:\n",
    "        links_in_table_df=pd.DataFrame(links).drop_duplicates()\n",
    "        links_in_table_df.columns=['link']\n",
    "        links_in_table_df['link']=links_in_table_df['link'].apply(filter_link) \n",
    "    else: \n",
    "        return None\n",
    "    return links_in_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ae0923",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_in_tables=[]\n",
    "for soup in soups:\n",
    "    links_in_tables.append(find_link_in_table(soup))\n",
    "\n",
    "links_in_tables_df=pd.concat(links_in_tables, axis=0)\n",
    "links_in_tables_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e69e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_in_tables_tot=len(links_in_tables_df)\n",
    "print('The total number of links in tables captions is {0}.'.format(links_in_tables_tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a45a032",
   "metadata": {},
   "source": [
    "The dataframe `links_in_images` contains the links showing up in images' captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2fa97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse html file and search hyperlinks in the captions of div containing images \n",
    "\n",
    "def find_links_in_img(soup):\n",
    "    div = soup.find_all('div')\n",
    "\n",
    "    links=[]\n",
    "\n",
    "    for d in div:\n",
    "        if (d.find('a', class_=\"internal\")):\n",
    "            if (d.find('img', class_='thumbimage')):\n",
    "                caption=d.find('div', class_=\"thumbcaption\")\n",
    "                if (caption.find('a')):\n",
    "                    all_links=caption.find_all('a')\n",
    "                    for link in all_links:\n",
    "                        if 'class' not in link.attrs:\n",
    "                            link_title=link.text\n",
    "                            links.append(link_title)\n",
    "    if links:\n",
    "        links_in_image_df=pd.DataFrame(links).drop_duplicates()\n",
    "        links_in_image_df.columns=['link']\n",
    "        links_in_image_df['link']=links_in_image_df['link'].apply(filter_link) \n",
    "    else: \n",
    "        return None\n",
    "        links_in_image_df=pd.DataFrame()\n",
    "    return links_in_image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d89127",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_in_images=[]\n",
    "for soup in soups:\n",
    "    links_in_images.append(find_links_in_img(soup))\n",
    "\n",
    "\n",
    "links_in_images_df=pd.concat(links_in_images, axis=0)\n",
    "links_in_images_unique=pd.Series(links_in_images_df['link'].unique(), name='link')\n",
    "links_in_images_unique.to_csv('links_in_images_unique.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fc8baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_in_images_tot=len(links_in_images_df)\n",
    "print('The total number of links in images captions is {0}.'.format(links_in_images_tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33914a38",
   "metadata": {},
   "source": [
    "Next, the supposed clickability preference for a hyperlink showing up in an image will be investigated, by grouping the click frequency by hyperlinks' location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07264623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop indexes to ease the flagging\n",
    "links_in_images_df=links_in_images_df.reset_index(drop=True)\n",
    "links_in_tables_df=links_in_tables_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d7b169",
   "metadata": {},
   "source": [
    "The dataframe `links_freq_img` contains hyperlinks click frequency and a flag specifying if they can be found in images' captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1342733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# link in image\n",
    "\n",
    "links_freq_img_f=links_freq_df_f.copy()\n",
    "links_freq_img_u=links_freq_df_u.copy()\n",
    "\n",
    "links_freq_img_f['in_image']=[1 if link in list(links_in_images_df['link']) else 0\n",
    "                           for link in links_freq_img_f['link']]\n",
    "links_freq_img_u['in_image']=[1 if link in list(links_in_images_df['link']) else 0\n",
    "                           for link in links_freq_img_u['link']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d8f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_freq_img_f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dcc54e",
   "metadata": {},
   "source": [
    "The dataframe `links_freq_tab` contains hyperlinks click frequency and a flag specifying if they can be found in tables' captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e19757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# link in table\n",
    "\n",
    "links_freq_tab_f=links_freq_df_f.copy()\n",
    "links_freq_tab_u=links_freq_df_u.copy()\n",
    "\n",
    "links_freq_tab_f['in_tab']=[1 if link in list(links_in_tables_df['link']) else 0\n",
    "                           for link in links_freq_tab_f['link']]\n",
    "links_freq_tab_u['in_tab']=[1 if link in list(links_in_tables_df['link']) else 0\n",
    "                               for link in links_freq_tab_u['link']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067c7d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find normalized values of clicks (#_clicks) on the basis of the relative number of times a hyperlink shows up in an \n",
    "# image caption to occurrence in the article text \n",
    "\n",
    "# images \n",
    "\n",
    "links_in_img=pd.concat(links_in_images, axis=0).reset_index(drop=True)\n",
    "\n",
    "link_in_img_freq_df=pd.DataFrame(links_in_img['link'].value_counts()).reset_index()\n",
    "link_in_img_freq_df.columns=['link', '#_link_in_img']\n",
    "link_in_img_freq_df.to_csv('link_in_img_freq_df.csv')\n",
    "link_in_img_freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb1c636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# links showing up in articles\n",
    "\n",
    "link_in_article=pd.concat(link_positioning_dfs, axis=0)['link']\n",
    "\n",
    "link_in_article_freq_df=pd.DataFrame(link_in_article.reset_index(drop=True).value_counts()).reset_index()\n",
    "link_in_article_freq_df.columns=['link', '#_link_in_article']\n",
    "link_in_article_freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a51760",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_f=pd.merge(links_freq_img_f, link_in_img_freq_df, how='left', left_on='link', right_on='link')\n",
    "new_df_img_f=pd.merge(df_img_f, link_in_article_freq_df, how='left', left_on='link', right_on='link')\n",
    "\n",
    "new_df_img_f['#_clicks'].fillna(0, inplace=True) #consider Nan frequency as 0\n",
    "new_df_img_f['#_link_in_article'].fillna(0, inplace=True) \n",
    "new_df_img_f['#_link_in_img'].fillna(0, inplace=True) \n",
    "new_df_img_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056ec262",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_u=pd.merge(links_freq_img_u, link_in_img_freq_df, how='left', left_on='link', right_on='link')\n",
    "new_df_img_u=pd.merge(df_img_u, link_in_article_freq_df, how='left', left_on='link', right_on='link')\n",
    "\n",
    "new_df_img_u['#_clicks'].fillna(0, inplace=True)\n",
    "new_df_img_u['#_link_in_article'].fillna(0, inplace=True)\n",
    "new_df_img_u['#_link_in_img'].fillna(0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d66ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_freq_img_f[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57077ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_values_img_f=new_df_img_f.loc[new_df_img_f['in_image']==1,'#_link_in_img']/new_df_img_f.loc[new_df_img_f['in_image']==1,'#_link_in_article'] #link in text counts also the clicks in images captions\n",
    "\n",
    "links_freq_img_f_norm=links_freq_img_f.copy()\n",
    "links_freq_img_f_norm.loc[norm_values_img_f.index, '#_clicks']=(links_freq_img_f_norm.loc[norm_values_img_f.index,'#_clicks']*norm_values_img_f)\n",
    "links_freq_img_f_norm.rename(columns={'#_clicks':'#_clicks_norm'}, inplace=True)\n",
    "links_freq_img_f_norm['#_clicks_norm']=links_freq_img_f_norm['#_clicks_norm'].round(2)\n",
    "links_freq_img_f_norm['#_clicks_norm'].replace(to_replace=np.inf, value=0, inplace=True)\n",
    "links_freq_img_f_norm[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca5b308",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_values_img_u=new_df_img_u.loc[new_df_img_u['in_image']==1,'#_link_in_img']/new_df_img_u.loc[new_df_img_u['in_image']==1,'#_link_in_article'] #link in text counts also the clicks in images captions\n",
    "\n",
    "links_freq_img_u_norm=links_freq_img_u.copy()\n",
    "links_freq_img_u_norm.loc[norm_values_img_u.index, '#_clicks']=(links_freq_img_u_norm.loc[norm_values_img_u.index,'#_clicks']*norm_values_img_u)\n",
    "links_freq_img_u_norm.rename(columns={'#_clicks':'#_clicks_norm'}, inplace=True)\n",
    "links_freq_img_u_norm['#_clicks_norm']=links_freq_img_u_norm['#_clicks_norm'].round(2)\n",
    "links_freq_img_u_norm['#_clicks_norm'].replace(to_replace=np.inf, value=0, inplace=True)\n",
    "\n",
    "links_freq_img_u_norm[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43456689",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_freq_img_f_norm.to_csv('links_freq_img_f_norm.csv')\n",
    "links_freq_img_u_norm.to_csv('links_freq_img_u_norm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89369a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tables \n",
    "\n",
    "#links_in_tab=pd.concat(links_in_tables, axis=0).reset_index(drop=True)\n",
    "#\n",
    "#link_in_tab_freq=[]\n",
    "#link_name=[]\n",
    "#\n",
    "#for link in list(links_in_tab['link']):\n",
    "#    count=list(links_in_tab['link']).count(link)\n",
    "#    link_name.append(link)\n",
    "#    link_in_tab_freq.append(count)\n",
    "#\n",
    "#link_name=pd.Series(link_name)\n",
    "#link_in_tab_freq=pd.Series(link_in_tab_freq)\n",
    "#link_in_tab_freq_df=pd.concat([link_name, link_in_tab_freq], axis=1)\n",
    "#link_in_tab_freq_df.columns=['link', '#_link_in_tab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e853197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#links_in_text=pd.concat(link_positioning_dfs, axis=0)['link']\n",
    "#link_in_text_freq=[]\n",
    "#link_name=[]\n",
    "#\n",
    "#for link in list(links_in_tab['link']):\n",
    "#    count=list(links_in_text).count(link)\n",
    "#    link_name.append(link)\n",
    "#    link_in_text_freq.append(count)\n",
    "#\n",
    "#link_name_text=pd.Series(link_name)\n",
    "#link_in_text_freq=pd.Series(link_in_text_freq)\n",
    "#link_in_text_freq_df=pd.concat([link_name_text, link_in_text_freq], axis=1)\n",
    "#link_in_text_freq_df.columns=['link', '#_link_in_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb2dc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tab=pd.merge(links_freq_tab[links_freq_tab['in_tab']==1], link_in_tab_freq_df, left_on='link', right_on='link')\n",
    "#new_df_tab=pd.merge(df_tab, link_in_text_freq_df, left_on='link', right_on='link')\n",
    "#new_df_tab=new_df_tab.set_index('link')\n",
    "#\n",
    "#norm_values_tab=new_df_tab['#_link_in_tab']/new_df_tab['#_link_in_text']\n",
    "#clicks_norm_tab=(new_df_tab['#_clicks']*norm_values_tab)\n",
    "#clicks_norm_tab.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "#clicks_norm_tab=clicks_norm_tab.fillna(0).values.astype('int')\n",
    "#\n",
    "#links_freq_tab=links_freq_tab.set_index('link')\n",
    "#links_freq_tab.rename(columns={'#_clicks':'#_clicks_norm'}, inplace=True)\n",
    "#links_freq_tab.loc[norm_values_tab.index,'#_clicks_norm']=clicks_norm_tab\n",
    "#links_freq_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc8c4cf",
   "metadata": {},
   "source": [
    "The dataframe `links_freq_img_grouped_df` contains the frequency of clicks for hyperlinks showing up in images' captions and not, and their normalized values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad62316",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_freq_img_grouped_df_f=pd.DataFrame(links_freq_img_f_norm['#_clicks_norm'].groupby(links_freq_img_f_norm['in_image']).sum())\n",
    "\n",
    "links_freq_img_grouped_df_f.loc[0,'#_clicks / #_links_img']=links_freq_img_grouped_df_f.loc[0,'#_clicks_norm']/(links_tot-links_in_images_tot)\n",
    "links_freq_img_grouped_df_f.loc[1,'#_clicks / #_links_img']=links_freq_img_grouped_df_f.loc[1,'#_clicks_norm']/links_in_images_tot\n",
    "\n",
    "links_freq_img_grouped_df_f['is_successful']=1\n",
    "links_freq_img_grouped_df_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf255a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_freq_img_grouped_df_u=pd.DataFrame(links_freq_img_u_norm['#_clicks_norm'].groupby(links_freq_img_u_norm['in_image']).sum())\n",
    "\n",
    "links_freq_img_grouped_df_u.loc[0,'#_clicks / #_links_img']=links_freq_img_grouped_df_u.loc[0,'#_clicks_norm']/(links_tot-links_in_images_tot)\n",
    "links_freq_img_grouped_df_u.loc[1,'#_clicks / #_links_img']=links_freq_img_grouped_df_u.loc[1,'#_clicks_norm']/links_in_images_tot\n",
    "\n",
    "links_freq_img_grouped_df_u['is_successful']=0\n",
    "links_freq_img_grouped_df_u\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e310a17",
   "metadata": {},
   "source": [
    "The dataframe `links_freq_tab_grouped_df` contains the frequency of clicks for hyperlinks showing up in tables' captions and not, and their normalized values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfca42d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#links_freq_tab_grouped_df=pd.DataFrame(links_freq_tab['#_clicks_norm'].groupby(links_freq_tab['in_tab']).sum())\n",
    "#\n",
    "#links_freq_tab_grouped_df.loc[0,'#_clicks/#_links_tab']=links_freq_tab_grouped_df.loc[0,'#_clicks_norm']/(links_tot-links_in_tables_tot)\n",
    "#links_freq_tab_grouped_df.loc[1,'#_clicks/#_links_tab']=links_freq_tab_grouped_df.loc[1,'#_clicks_norm']/links_in_tables_tot\n",
    "#\n",
    "#links_freq_tab_grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986cd676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe for visualization\n",
    "#vis_img=links_freq_img_grouped_df.merge(links_freq_tab_grouped_df, left_index=True, right_index=True)\n",
    "#\n",
    "#fig, ax = plt.subplots(figsize=(6,5))\n",
    "#vis_img.plot(y=['#_clicks/#_links_img', '#_clicks/#_links_tab'], kind='bar', ax=ax, label=['image', 'table'], color=['orange', 'green'])\n",
    "#ax.legend()\n",
    "#ax.set_xlabel('Link in image or table caption')\n",
    "#ax.set_ylabel('#_clicks/#_hyperlinks')\n",
    "#ax.set_title('Distribution of hyperlinks in captions clickability preference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03711d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f24398",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_img=pd.concat([links_freq_img_grouped_df_f, links_freq_img_grouped_df_u], axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8), sharey=True)\n",
    "\n",
    "sns.barplot(y='#_clicks / #_links_img', x=vis_img.index, data=vis_img, palette=sns.color_palette(\"Set2\"), hue='is_successful', edgecolor='k')\n",
    "\n",
    "ax.set_title('Distribution of clickability preference', fontsize=18)\n",
    "ax.set_xlabel('Positioning', fontsize=18)\n",
    "ax.set_ylabel('#_clicks / #_hyperlinks', fontsize=18)\n",
    "ax.legend_.set_title('')\n",
    "labels = ['Unsuccessful', 'Successful']\n",
    "for t, l in zip(ax.legend_.texts, labels):\n",
    "    t.set_text(l)\n",
    "plt.savefig('Distribution_clickability_preference_img.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebb5d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_img.to_csv('vis_img.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53ebe87",
   "metadata": {},
   "source": [
    "There is an evident players' clicability preference for hyperlinks showing up in images, both among successful and unsuccessful players. <br>\n",
    "Moreover, succesfull players click on average more than unsuccessful ones.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df016b6",
   "metadata": {},
   "source": [
    "Assumptions: \n",
    "1. when a hyperlink shows up in both the article text and in an image caption, it is not possible to extract from the data in our possess what the player's click choice perfomed is. Therefore we assumed that hyperlinks showing up in images' captions don't appear in the text, as the following statement justifies. The normalization, therefore took into account a total number of links in texts equal to  (total number of hyperlinks detected) - (total number of hyperlinks showing up in images' captions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59738c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "twice=0\n",
    "for idx in range(len(link_positioning_dfs)):\n",
    "    if links_in_images[idx] is None:\n",
    "        continue\n",
    "    else:\n",
    "        if set(link_positioning_dfs[idx]['link']).intersection(set(links_in_images[idx]['link'])):\n",
    "            twice+=1\n",
    "print('{0} hyperlinks show up both in the text and in an image caption of an article, out of {1} articles.'.format(twice, len(link_positioning_dfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb27d41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2006ced2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8bd9dff",
   "metadata": {},
   "source": [
    "## Regression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cadbcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lenghts_f=[len(path) for path in clicked_links_filtered_f]\n",
    "path_lenghts_u=[len(path) for path in clicked_links_filtered_u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e3da6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(paths_list):\n",
    "    features=[]\n",
    "    for path in paths_list:\n",
    "        features.append([most_freq_positioning_df.loc[link].values.item() \n",
    "                         if link in most_freq_positioning_df.index else np.random.choice(['top', 'center-top','center','center-bottom', 'bottom'])\n",
    "                         for link in path])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ec9b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to discuss: 3% of links do not show up in most_freq_positioning_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8570a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_f=find_features(clicked_links_filtered_f)\n",
    "features_u=find_features(clicked_links_filtered_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab735ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features_frequency(features):\n",
    "    t=[]\n",
    "    ct=[]\n",
    "    c=[]\n",
    "    cb=[]\n",
    "    b=[]    \n",
    "    for path in features:\n",
    "        t.append(path.count('top'))\n",
    "        ct.append(path.count('center-top'))\n",
    "        c.append(path.count('center'))\n",
    "        cb.append(path.count('center-bottom'))\n",
    "        b.append(path.count('bottom'))\n",
    "    return pd.DataFrame({'top': t, 'center_top': ct, 'center': c, 'center_bottom': cb, 'bottom': b})\n",
    "\n",
    "features_frequency_f=find_features_frequency(features_f)\n",
    "features_frequency_u=find_features_frequency(features_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c486244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features_category(features):\n",
    "    t=[]\n",
    "    ct=[]\n",
    "    c=[]\n",
    "    cb=[]\n",
    "    b=[]    \n",
    "    for path in features:\n",
    "        t.append(1 if 'top' in path else 0)\n",
    "        ct.append(1 if 'center-top' in path else 0)\n",
    "        c.append(1 if 'center' in path else 0)\n",
    "        cb.append(1 if 'center-bottom' in path else 0)\n",
    "        b.append(1 if 'bottom' in path else 0)\n",
    "    return pd.DataFrame({'top': t, 'center_top': ct, 'center': c, 'center_bottom': cb, 'bottom': b})\n",
    "\n",
    "features_categorical_f=find_features_category(features_f)\n",
    "features_categorical_u=find_features_category(features_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b084bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats import diagnostic\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c4eb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df_f=pd.concat([pd.Series(path_lenghts_f, name='pathlength'), features_frequency_f], axis=1)\n",
    "reg_df_u=pd.concat([pd.Series(path_lenghts_u, name='pathlength'), features_frequency_u], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931c3194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize features (e.g. #_top_links in path/len(path)) \n",
    "\n",
    "def norm_features(df):\n",
    "    df_new=pd.DataFrame()\n",
    "    for c in df.columns[1:]:\n",
    "        df_new[c]=df[c]/df['pathlength']\n",
    "    return df_new\n",
    "\n",
    "#standardize features \n",
    "\n",
    "def standardize_features(df):\n",
    "    df_std=pd.DataFrame()\n",
    "    for c in df.columns:\n",
    "        df_std[c]=(df[c]-df[c].mean())/df[c].std()\n",
    "    return df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f131546",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df_norm_f=norm_features(reg_df_f).reset_index(drop=True)  \n",
    "reg_df_norm_u=norm_features(reg_df_u).reset_index(drop=True)  \n",
    "\n",
    "reg_df_norm_std_f=standardize_features(reg_df_norm_f)\n",
    "reg_df_norm_std_u=standardize_features(reg_df_norm_u)\n",
    "\n",
    "reg_df_norm_std_f['success']=1\n",
    "reg_df_norm_std_u['success']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cebb5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg_df_norm_std_u=pd.concat([reg_df_norm_std_f, reg_df_norm_std_u], axis=0)\n",
    "\n",
    "mod= smf.logit(formula='success ~ top + center_top + center + center_bottom + bottom', data=reg_df_norm_std_u)\n",
    "res=mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a740f131",
   "metadata": {},
   "source": [
    "unitary p-values, all coefficients not significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aad85ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_C_df_f=pd.concat([pd.Series(path_lenghts_f, name='pathlength'), features_categorical_f], axis=1)\n",
    "reg_C_df_u=pd.concat([pd.Series(path_lenghts_u, name='pathlength'), features_categorical_u], axis=1)\n",
    "\n",
    "reg_C_df_f['success']=1\n",
    "reg_C_df_u['success']=0\n",
    "\n",
    "reg_C_df=pd.concat([reg_C_df_f, reg_C_df_u], axis=0)\n",
    "\n",
    "mod_C_f = smf.logit(formula='success ~ C(top) + C(center_top) + C(center) + C(center_bottom) + C(bottom)', data=reg_C_df)\n",
    "res_C_f=mod_C_f.fit()\n",
    "print(res_C_f.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858189aa",
   "metadata": {},
   "source": [
    "# Matched analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064885e2",
   "metadata": {},
   "source": [
    "## Hyperlinks positioning clickability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eeb609",
   "metadata": {},
   "source": [
    "The methodology chosen for the data processing step is to perform a matched analysis (allowing to obtain actually comparable data) aimed at testing if specific human game strategies lead to success in the Wikispeedia game. \n",
    "A logistic regression is conducted with the goal of estimating the parameters of the logistic model with the dependent binary variable being the success (or NOT success) and the independent variables being sequentially extracted the following set of features (different human behaviors/choices when playing the Wikispeedia game):\n",
    "1. Positioning of the clicked hyperlinks;\n",
    "2. Clicking hyperlinks in images’ captions. <br>\n",
    "\n",
    "Several confounders may affect the outcome of the regression analysis i.e. of the potentially found correlation between the aforementioned features and success. To mention a few, the “difficulty” of the randomly assigned task (source and target articles) to players, affects their successfulness together with the strategy adopted to address it. This “difficulty” could be naively measured by shortest path distance between the source and target article in the Wikispeedia hyperlinks graph (calculated with the Floyd-Warshall algorithm). Additionally the actual sequence of clicked hyperlinks (qualitative feature, w.r.t. semantics) and their numerosity along a path (quantitative feature) again reasonably affects players successfulness and their choice for a strategy.  \n",
    "In order to remove the aforementioned confounders, the dataset is filtered accordingly with the assumptions made. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0217c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_path_matrix = []\n",
    "\n",
    "with open(folder+'shortest-path-distance-matrix.txt', 'r') as f:\n",
    "    # the first 17 lines (indexed from 0) is the file description \n",
    "    for line in f.readlines()[17:]:\n",
    "        shortest_path_matrix.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0076b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shortest_path(paths_df: pd.DataFrame, successful: bool)-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    this function takes a DataFrame and returns a DataFrame with the following columns:\n",
    "       1. human path length\n",
    "       2. source article\n",
    "       3. target article\n",
    "       4. shortest path length\n",
    "       \n",
    "    input:\n",
    "       df: the DataFrame containing all the human navigation paths\n",
    "       successful or unsuccessful: a boolean indicating whether the paths were successful or not\n",
    "    \"\"\"\n",
    "    #get filtered list of paths and the indeces of the removed  \n",
    "    paths_list, removed_idxs=get_clicked_links(paths_df) \n",
    "    \n",
    "    human_path_lengths, source_articles, target_articles, shortest_path_lengths = [], [], [], []\n",
    "    \n",
    "    articles_list=list(articles.article) #list of articles \n",
    "    \n",
    "    \n",
    "    def get_source_target(paths_list, removed_idxs, successful):\n",
    "        \"\"\"this helper function takes the list of paths and a boolean indicating whether the paths were successfull or not\n",
    "        and returns the source and target articles for each path\"\"\"\n",
    "        target_articles, shortest_path_lengths = [], []\n",
    "        \n",
    "        for human_path in paths_list:\n",
    "\n",
    "            human_path_lengths.append(len(human_path)-1)\n",
    "\n",
    "            source=human_path[0]\n",
    "            source_articles.append(source)\n",
    "\n",
    "            if successful:\n",
    "                target=human_path[-1]\n",
    "                target_articles.append(target)\n",
    "        \n",
    "        #target articles for unsuccessful paths need to be extracted from the column 'target' of the df\n",
    "        if not successful:\n",
    "            target_articles=paths_df.drop(removed_idxs)['target'].apply(filter_link).reset_index(drop=True)\n",
    "            \n",
    "        return human_path_lengths, source_articles, target_articles\n",
    "    \n",
    "    human_path_lengths, source_articles, target_articles = get_source_target(paths_list, removed_idxs, successful)\n",
    "    \n",
    "    for source, target in zip(source_articles, target_articles):\n",
    "        \n",
    "        source_index = articles_list.index(source)\n",
    "        # there are target articles that were not provided in the plain text files\n",
    "        try:\n",
    "            target_index = articles_list.index(target)\n",
    "        except Exception:\n",
    "            shortest_path_lengths.append(\"N/A\")\n",
    "            continue\n",
    "\n",
    "        # query the shortest path matrix to get the correct vector (corresponding to the source article)\n",
    "        shortest_path_vector = shortest_path_matrix[source_index]\n",
    "        # now find the target article indexed integer in the vector\n",
    "        shortest = shortest_path_vector[target_index]\n",
    "        # it's not always possible to get to the target article. Impossible navigation is denoted by \"_\"\n",
    "        if shortest == \"_\":\n",
    "            shortest_path_lengths.append(\"Impossible\")\n",
    "        else:\n",
    "            shortest_path_lengths.append(int(shortest))\n",
    "        \n",
    "    return pd.DataFrame({'source_article': source_articles, 'target_article': target_articles, 'human_path_length': human_path_lengths, 'shortest_path_length': shortest_path_lengths})\n",
    "\n",
    "successful_df=get_shortest_path(paths_finished, True)\n",
    "unsuccessful_df=get_shortest_path(paths_unfinished, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36afc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ac9c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the label for each human path \n",
    "successful_df['is_successful']=1\n",
    "unsuccessful_df['is_successful']=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8fd532",
   "metadata": {},
   "source": [
    "Known the \"label\" of each human path, i.e. player's success (`is_successful`) (binary variable equal to 0 for unsuccessful players or 1 for unsuccessful players), its length (`human_path_length`) and the source (`source_article`), target (`target_article`) articles and shortest path distance on the Wikispeedia graph (`shortest_path_length`) of the assigned game, the features of each human path are extrapolated as follows:\n",
    "1. to each hyperlink clicked in the human path it is assigned its most frequent positioning*;\n",
    "2. for each path the distribution of the 5 categorical positioning (`top`, `center-top`, `center`, `center-bottom`,`bottom`) of hyperlinks is calculated (their relative frequency: numerical predictor).\n",
    "3. the values of the variables are standardized**. \n",
    "\n",
    "\\*its most frequent positioning is determined on the basis of its occurencies in the set of articles making up the Wikispeedia html files database. <br>\n",
    "\\*\\* they are not normalized on human path length, as the matching of the players will be done also on human path length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d125ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(paths_list):\n",
    "    '''this function determines the categorical positioning feature of each hyperlink in the human path'''\n",
    "    features=[]\n",
    "    for human_path in paths_list:\n",
    "        features.append([most_freq_positioning_df.loc[link].values.item() \n",
    "                         if link in most_freq_positioning_df.index \\\n",
    "                         else np.random.choice(['top', 'center-top','center','center-bottom', 'bottom'])\n",
    "                         for link in human_path]) #certain hyperlinks were not classified \n",
    "    return features\n",
    "\n",
    "successful_features=find_features(clicked_links_filtered_f)\n",
    "unsuccessful_features=find_features(clicked_links_filtered_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9af8135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features_frequency(features):\n",
    "    '''this function counts the frequency of the categorical positioning features of the hyperlinks in each human path'''\n",
    "    t, ct, c, cb, b=[], [], [], [], []\n",
    "\n",
    "    for path in features:\n",
    "        t.append(path.count('top'))\n",
    "        ct.append(path.count('center-top'))\n",
    "        c.append(path.count('center'))\n",
    "        cb.append(path.count('center-bottom'))\n",
    "        b.append(path.count('bottom'))\n",
    "    return pd.DataFrame({'top': t, 'center_top': ct, 'center': c, 'center_bottom': cb, 'bottom': b})\n",
    "\n",
    "successful_features_freq=find_features_frequency(successful_features)\n",
    "unsuccessful_features_freq=find_features_frequency(unsuccessful_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585fc673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize features \n",
    "\n",
    "def standardize_features(df):\n",
    "    df_std=pd.DataFrame()\n",
    "    for c in df.columns:\n",
    "        df_std[c]=(df[c]-df[c].mean())/df[c].std()\n",
    "    return df_std\n",
    "\n",
    "successful_features_std=standardize_features(successful_features_freq)\n",
    "unsuccessful_features_std=standardize_features(unsuccessful_features_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a4a524",
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_features_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b29c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete dataframe with label and features\n",
    "successful_positioning_df=pd.concat([successful_df, successful_features_std], axis=1)\n",
    "unsuccessful_positioning_df=pd.concat([unsuccessful_df, unsuccessful_features_std], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ac9a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_positioning_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dab5c42",
   "metadata": {},
   "source": [
    "In order to filter the dataframe for the matched analysis, aimed at removing the two highlighted potential confounders for the supposed causal relationship between strategy and success (i.e. difficulty of the game and number of choices performed by the player), a distribution of human path lengths and shortest path distances is plotted with the goal of evaluating the appropriate values of lengths to filter on. This step is essential in order to be able to run algorithms with such large datasets and it is justified as for certain lengths not enough data are provided, therefore any result inferred will be not statistically significant and robust. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422670a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of shortest path distance for successful players\n",
    "successful_positioning_df['shortest_path_length'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39482b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of shortest path distance for successful players\n",
    "unsuccessful_positioning_df['shortest_path_length'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d54ea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of human path length for successful players\n",
    "successful_positioning_df['human_path_length'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50a2439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of human path length for unsuccessful players\n",
    "unsuccessful_positioning_df['human_path_length'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a481a121",
   "metadata": {},
   "source": [
    "Human paths with length equal to 1 or 2 are filtered, even if they are the most frequent, as they are respectively associated with no choice performed (i.e. the player did not actually get away from the source article) and no  information on sequential behavior that can be extrapolated, as the player performed 1 choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b39491",
   "metadata": {},
   "source": [
    "The most numerous shortest path distance for both successful and unsuccessful players is 3. Since enough data (> 30000 inputs) is available filtering on this shortest path distance, it is employed. <br>\n",
    "The tree most frequent human path lengths for both successful and unsuccessful players are [3,4,5]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de16300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter on shortest path length\n",
    "successful_positioning_rel_df=successful_positioning_df.loc[successful_positioning_df['shortest_path_length'].isin([3])].reset_index(drop=True)\n",
    "unsuccessful_positioning_rel_df=unsuccessful_positioning_df.loc[unsuccessful_positioning_df['shortest_path_length'].isin([3])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1dca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter on human path length\n",
    "successful_positioning_rel_df=successful_positioning_rel_df.loc[successful_positioning_rel_df['human_path_length'].isin([3,4,5])].reset_index(drop=True)\n",
    "unsuccessful_positioning_rel_df=unsuccessful_positioning_rel_df.loc[unsuccessful_positioning_rel_df['human_path_length'].isin([3,4,5])].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72801d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_positioning_rel_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8728aa",
   "metadata": {},
   "source": [
    "The matching is carried out with the following properties:\n",
    "- treated subject: user performing a specific strategy;\n",
    "- controlled subject: user NOT performing a specific strategy\n",
    "  1. clicking more than the average on top-positioned hyperlinks in articles' texts;\n",
    "  2. clicking more than the average on center-bottom-positioned hyperlinks in the articles' texts;\n",
    "- match on shortest path distance*;\n",
    "- match on human path distance.\n",
    "\n",
    "\\*this constraint is already met, as the dataset is filtered on a unique shortest path distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f91ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2873e06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe input of the matching algorithm\n",
    "unbalanced_positioning_df=pd.concat([successful_positioning_rel_df, unsuccessful_positioning_rel_df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d17e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "unbalanced_positioning_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13ef22e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3df513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d973cf97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f883580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matching for top-positioned hyperlinks clicking behavior\n",
    "\n",
    "# Separate the treatment and control groups\n",
    "treatment_df = unbalanced_positioning_df[unbalanced_positioning_df['top']>= 0]\n",
    "control_df = unbalanced_positioning_df[unbalanced_positioning_df['top'] < 0]\n",
    "\n",
    "# Create an empty undirected graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Loop through all the pairs of instances\n",
    "for control_id, control_row in control_df.iterrows():\n",
    "    for treatment_id, treatment_row in treatment_df.iterrows():\n",
    "\n",
    "        if control_row['human_path_length'] == treatment_row['human_path_length']: #match by shortest path length\n",
    "            #Add an edge between the two instances \n",
    "            G.add_edge(control_id, treatment_id)\n",
    "\n",
    "# Generate and return the maximum weight matching on the generated graph\n",
    "matching = nx.max_weight_matching(G)\n",
    "matched = [i[0] for i in list(matching)] + [i[1] for i in list(matching)]\n",
    "balanced_pos_df = unbalanced_pos_df.iloc[matched]\n",
    "\n",
    "\n",
    "balanced_pos_df.to_csv('top_balanced_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cc7ef9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e0cba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_pos_df['success'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e9d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "for treatment in ['top', 'center-bottom']:\n",
    "\n",
    "    treatment_df = unbalanced_positioning_df[unbalanced_positioning_df[treatment] >= 0]\n",
    "    control_df = unbalanced_positioning_df[unbalanced_positioning_df[treatment] < 0]\n",
    "\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for control_id, control_row in control_df.iterrows():\n",
    "        for treatment_id, treatment_row in treatment_df.iterrows():\n",
    "            # Adds an edge only for the same human path length\n",
    "            if (control_row['human_path_length'] == treatment_row['human_path_length']):\n",
    "                G.add_edge(control_id, treatment_id)\n",
    "\n",
    "    matching = nx.max_weight_matching(G)\n",
    "    matched = [i[0] for i in list(matching)] + [i[1] for i in list(matching)]\n",
    "    balanced_df = final_df.iloc[matched]\n",
    "\n",
    "    # save balanced_df\n",
    "    balanced_df.to_csv(f'{treatment}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa76890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_top = smf.logit(formula='success ~ center_bottom', data=balanced_pos_df)\n",
    "res_top = mod_top.fit()\n",
    "print(res_top.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1c0db7",
   "metadata": {},
   "source": [
    "## Hyperlinks in images' captions clickability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b785dcb",
   "metadata": {},
   "source": [
    "The dataframe containing the \"label\" of each human path (`is_successful`), its length (`human_path_length`) and the source (`source_article`), target (`target_article`) articles and shortest path distance on the Wikispeedia graph (`shortest_path_length`) of the assigned game is already available. The feature holding the information on hyperlinks in image captions clickability is extrapolated as follows:\n",
    "1. for each human path the numerosity of hyperlinks showing up in images captions is counted (numerical predictor). \n",
    "2. the value is standardized*.\n",
    "\n",
    "\\* not normalized on human path length, as the matching of the players will be done also on human path length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c28314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of unique hyperlinks showing up in images'captions\n",
    "links_in_img=links_in_images_df['link'].unique() \n",
    "\n",
    "#count number of hyperlinks in images' captions in each path\n",
    "successful_img_freq=[np.isin(path, links_in_img).sum() if np.isin(path, links_in_img).sum() else 0 for path in clicked_links_filtered_f]\n",
    "unsuccessful_img_freq=[np.isin(path, links_in_img).sum() if np.isin(path, links_in_img).sum() else 0 for path in clicked_links_filtered_u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0698aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete dataframe with label and features\n",
    "successful_img_df=pd.concat([successful_df, pd.Series(successful_img_freq, name='img_freq')], axis=1)\n",
    "unsuccessful_img_df=pd.concat([unsuccessful_df, pd.Series(unsuccessful_img_freq, name='img_freq')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaa6dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize features\n",
    "successful_img_df['img_freq']=(successful_img_df['img_freq']-successful_img_df['img_freq'].mean())/successful_img_df['img_freq'].std()\n",
    "unsuccessful_img_df['img_freq']=(unsuccessful_img_df['img_freq']-unsuccessful_img_df['img_freq'].mean())/unsuccessful_img_df['img_freq'].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e258aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter on shortest path length\n",
    "successful_img_rel_df=successful_img_df.loc[successful_img_df['shortest_path_length'].isin([3])]\n",
    "unsuccessful_img_rel_df=unsuccessful_img_df.loc[unsuccessful_img_df['shortest_path_length'].isin([3])]\n",
    "#filter on human path length\n",
    "successful_img_rel_df=successful_img_rel_df.loc[successful_img_rel_df['human_path_length'].isin([3,4,5])].reset_index(drop=True)\n",
    "unsuccessful_img_rel_df=unsuccessful_img_rel_df.loc[unsuccessful_img_rel_df['human_path_length'].isin([3,4,5])].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a64c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "unbalanced_img_df=pd.concat([successful_img_rel_df, unsuccessful_img_rel_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aedf8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "unbalanced_img_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481f5b6d",
   "metadata": {},
   "source": [
    "The matching is carried out as before with:\n",
    "- treated subject: user clicking more than the average on hyperlinks in images' caption;\n",
    "- controlled subject: user NOT performing this strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f170fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the treatment and control groups\n",
    "treatment_df = unbalanced_img_df[unbalanced_img_df['img_freq']>=0]\n",
    "control_df = unbalanced_img_df[unbalanced_img_df['img_freq'] < 0]\n",
    "\n",
    "# Create an empty undirected graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Loop through all the pairs of instances\n",
    "for control_id, control_row in control_df.iterrows():\n",
    "    for treatment_id, treatment_row in treatment_df.iterrows():\n",
    "\n",
    "        if control_row['human_path_length'] == treatment_row['human_path_length']: #match by shortest path lenght\n",
    "            #Add an edge between the two instances weighted by the similarity between them\n",
    "            G.add_edge(control_id, treatment_id)\n",
    "\n",
    "# Generate and return the maximum weight matching on the generated graph\n",
    "matching = nx.max_weight_matching(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988a6a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get balanced df\n",
    "matched = [i[0] for i in list(matching)] + [i[1] for i in list(matching)]\n",
    "balanced_img_df = unbalanced_img_df.iloc[matched]\n",
    "balanced_img_df['success'].value_counts()\n",
    "balanced_img_df.to_csv('img_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f019c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe input of the matching algorithm\n",
    "balanced_img_df=read_csv(folder+'img_df.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f025f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_img = smf.logit(formula='success ~ img_freq', data=balanced_img_df)\n",
    "res_img = mod_img.fit()\n",
    "print(res_img.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda27ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a0bb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count how many data we would have if matching on source and target article\n",
    "successful_df.groupby(by=['source_article', 'target_article']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0401f26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(successful_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
