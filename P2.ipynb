{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9f0b041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f12a423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for reading all HTLM files in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd6a6e28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r/Royal_Marines.htm',\n",
       " 'r/Recycling.htm',\n",
       " 'r/Retreat_of_glaciers_since_1850.htm',\n",
       " 'r/Remember_Girls_Like_Rajpura.htm',\n",
       " 'r/Rutherfordium.htm',\n",
       " 'r/Rule_of_St_Benedict.htm',\n",
       " 'r/Red_dwarf.htm',\n",
       " 'r/Romeo_and_Juliet.htm',\n",
       " 'r/Rudyard_Kipling.htm',\n",
       " 'r/Race.htm',\n",
       " 'r/Ruthenium.htm',\n",
       " 'r/Rail_transport_in_India.htm',\n",
       " 'r/Renormalization.htm',\n",
       " 'r/Rosetta_Stone.htm',\n",
       " 'r/Rupee.htm',\n",
       " 'r/Rondane_National_Park.htm',\n",
       " 'r/Russian_constitutional_crisis_of_1993.htm',\n",
       " 'r/Richard_Wagner.htm',\n",
       " 'r/Roman_mythology.htm',\n",
       " 'r/Rudolf_Vrba.htm',\n",
       " 'r/Richard_Nixon.htm',\n",
       " 'r/Roman_Catholic_Church.htm',\n",
       " 'r/Richard_Feynman.htm',\n",
       " 'r/Roman_law.htm',\n",
       " 'r/Royal_Grammar_School_Worcester.htm',\n",
       " 'r/Rosemary.htm',\n",
       " 'r/Roman_road.htm',\n",
       " 'r/Royal_Geographical_Society.htm',\n",
       " 'r/Radio_telescope.htm',\n",
       " 'r/Rome.htm',\n",
       " 'r/Royal_Dutch_Shell.htm',\n",
       " 'r/Refrigerator_car.htm',\n",
       " 'r/Roald_Amundsen.htm',\n",
       " 'r/Roman_villa.htm',\n",
       " 'r/Robert_Oppenheimer.htm',\n",
       " 'r/Rabat.htm',\n",
       " 'r/Richard_Stallman.htm',\n",
       " 'r/Reigate_Wow_Balloon_Launch.htm',\n",
       " 'r/Rook_%28bird%29.htm',\n",
       " 'r/Renaissance.htm',\n",
       " 'r/Radon.htm',\n",
       " 'r/Radar.htm',\n",
       " 'r/Roan_Antelope.htm',\n",
       " 'r/Roche_limit.htm',\n",
       " 'r/Riyadh.htm',\n",
       " 'r/Rhodium.htm',\n",
       " 'r/Richard_Francis_Burton.htm',\n",
       " 'r/Ragtime.htm',\n",
       " 'r/Republic_of_China.htm',\n",
       " 'r/Report_From_Chernobyl.htm',\n",
       " 'r/Red_rain_in_Kerala.htm',\n",
       " 'r/Rubik%27s_Cube.htm',\n",
       " 'r/Rose-ringed_Parakeet.htm',\n",
       " 'r/Rhode_Island.htm',\n",
       " 'r/Robert_Gascoyne-Cecil%2C_3rd_Marquess_of_Salisbury.htm',\n",
       " 'r/Raising_the_Flag_on_Iwo_Jima.htm',\n",
       " 'r/Rugby_football.htm',\n",
       " 'r/Rwanda.htm',\n",
       " 'r/Ramsgate.htm',\n",
       " 'r/Ramayana.htm',\n",
       " 'r/Rugby_World_Cup.htm',\n",
       " 'r/River.htm',\n",
       " 'r/Richard_O%27Connor.htm',\n",
       " 'r/Recorder.htm',\n",
       " 'r/Ray_of_Light.htm',\n",
       " 'r/Ren%C3%A9_Descartes.htm',\n",
       " 'r/Romania_A.htm',\n",
       " 'r/Rhenium.htm',\n",
       " 'r/Railway_post_office.htm',\n",
       " 'r/RSS_%28file_format%29.htm',\n",
       " 'r/Richard_III_%28play%29.htm',\n",
       " 'r/Right_whale.htm',\n",
       " 'r/Red_Panda.htm',\n",
       " 'r/Royal_Air_Force.htm',\n",
       " 'r/Redshift.htm',\n",
       " 'r/Rembrandt.htm',\n",
       " 'r/Radio.htm',\n",
       " 'r/Royal_Navy.htm',\n",
       " 'r/Rowan_Williams.htm',\n",
       " 'r/Republic_of_the_Congo.htm',\n",
       " 'r/Robert_Schumann.htm',\n",
       " 'r/Rock_of_Gibraltar.htm',\n",
       " 'r/Richard_I_of_England.htm',\n",
       " 'r/Russia.htm',\n",
       " 'r/Roman_Greece.htm',\n",
       " 'r/Robert_Stephenson.htm',\n",
       " 'r/Reza_Shah.htm',\n",
       " 'r/Retina.htm',\n",
       " 'r/Rococo.htm',\n",
       " 'r/Rutherford_B._Hayes.htm',\n",
       " 'r/Richard_II_of_England.htm',\n",
       " 'r/Renaissance_music.htm',\n",
       " 'r/Russian_language.htm',\n",
       " 'r/Restoration_comedy.htm',\n",
       " 'r/Roman_Empire.htm',\n",
       " 'r/River_Severn.htm',\n",
       " 'r/Rabbit.htm',\n",
       " 'r/Rosa_Parks.htm',\n",
       " 'r/Reggae.htm',\n",
       " 'r/Red_giant.htm']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "wp_path = \"/Users/ginevralarroux/Desktop/EPFL courses/Applied data analysis/ADA project/data/wpcd/wp/\" # to adapt\n",
    "directories = os.listdir(wp_path)\n",
    "\n",
    "html_list = []\n",
    "for dir in directories:\n",
    "    local_path = wp_path + dir\n",
    "    local_dir = os.listdir(local_path)\n",
    "    for link in local_dir:\n",
    "        if link[-3:]=='htm':\n",
    "            html_list.append(dir+'/'+link)\n",
    "        \n",
    "html_list=html_list[:100] # parse 100 of them\n",
    "html_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4abdba1",
   "metadata": {},
   "source": [
    "The aim of this specific game strategy analysis is to test whether Wikispeedia players have clikability preferences on the basis of the hyperlinks' positioning throughout the article text. \n",
    "In particular:\n",
    "1. we wil find the ordinal number of paragraph each hyperlink shows up in and divide it by the total number of paragraphs of the article, to determine its positioning; \n",
    "2. we will find if each clicked hyperlink shows up in images' captions in the article.\n",
    "We will then investigate if there is a correlation between the clickability of the hyperlinks and their location, using the most appropriate statistical tests. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367618fb",
   "metadata": {},
   "source": [
    "It is therefore essential to extract from the data the frequency of clicks for each hyperlink."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "500c58ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for extracting the hyperlinks click frequency  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb1a99ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder='/Users/ginevralarroux/Desktop/EPFL courses/Applied data analysis/ADA project/data/wikispeedia_paths-and-graph/'\n",
    "\n",
    "paths_finished='paths_finished.tsv'\n",
    "articles='articles.tsv'\n",
    "\n",
    "paths_finished=pd.read_csv(folder+paths_finished, sep='\\t', skiprows=15, header=None, names=['hashedIpAddress', 'timestamp', 'durationInSec', 'path', 'rating'])\n",
    "articles=pd.read_csv(folder+articles, sep='\\t', skiprows=12, header=None, names=['article'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b35d62",
   "metadata": {},
   "source": [
    "This dataframe contains the paths chosen by the players who could reach the target article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2e72681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashedIpAddress</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>durationInSec</th>\n",
       "      <th>path</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6a3701d319fc3754</td>\n",
       "      <td>1297740409</td>\n",
       "      <td>166</td>\n",
       "      <td>14th_century;15th_century;16th_century;Pacific...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3824310e536af032</td>\n",
       "      <td>1344753412</td>\n",
       "      <td>88</td>\n",
       "      <td>14th_century;Europe;Africa;Atlantic_slave_trad...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>415612e93584d30e</td>\n",
       "      <td>1349298640</td>\n",
       "      <td>138</td>\n",
       "      <td>14th_century;Niger;Nigeria;British_Empire;Slav...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64dd5cd342e3780c</td>\n",
       "      <td>1265613925</td>\n",
       "      <td>37</td>\n",
       "      <td>14th_century;Renaissance;Ancient_Greece;Greece</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>015245d773376aab</td>\n",
       "      <td>1366730828</td>\n",
       "      <td>175</td>\n",
       "      <td>14th_century;Italy;Roman_Catholic_Church;HIV;R...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hashedIpAddress   timestamp  durationInSec  \\\n",
       "0  6a3701d319fc3754  1297740409            166   \n",
       "1  3824310e536af032  1344753412             88   \n",
       "2  415612e93584d30e  1349298640            138   \n",
       "3  64dd5cd342e3780c  1265613925             37   \n",
       "4  015245d773376aab  1366730828            175   \n",
       "\n",
       "                                                path  rating  \n",
       "0  14th_century;15th_century;16th_century;Pacific...     NaN  \n",
       "1  14th_century;Europe;Africa;Atlantic_slave_trad...     3.0  \n",
       "2  14th_century;Niger;Nigeria;British_Empire;Slav...     NaN  \n",
       "3     14th_century;Renaissance;Ancient_Greece;Greece     NaN  \n",
       "4  14th_century;Italy;Roman_Catholic_Church;HIV;R...     3.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths_finished.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00681d55",
   "metadata": {},
   "source": [
    "This dataframe lists all the clickable articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8d25afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>%c3%81ed%c3%a1n mac gabr%c3%a1in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>%c3%85land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>%c3%89douard manet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>%c3%89ire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>%c3%93engus i of the picts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            article\n",
       "0  %c3%81ed%c3%a1n mac gabr%c3%a1in\n",
       "1                        %c3%85land\n",
       "2                %c3%89douard manet\n",
       "3                         %c3%89ire\n",
       "4        %c3%93engus i of the picts"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_article_name(article_list):\n",
    "    new_article_list=[]\n",
    "    for article in article_list:\n",
    "        article = article.lower()\n",
    "        article = article.replace('_', ' ')\n",
    "        article = article.strip()\n",
    "        new_article_list.append(article)\n",
    "    return new_article_list\n",
    "\n",
    "articles.article=filter_article_name(articles.article)\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c973fe98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['14th century',\n",
       "  '15th century',\n",
       "  '16th century',\n",
       "  'pacific ocean',\n",
       "  'atlantic ocean',\n",
       "  'accra',\n",
       "  'africa',\n",
       "  'atlantic slave trade',\n",
       "  'african slave trade'],\n",
       " ['14th century',\n",
       "  'europe',\n",
       "  'africa',\n",
       "  'atlantic slave trade',\n",
       "  'african slave trade'],\n",
       " ['14th century',\n",
       "  'niger',\n",
       "  'nigeria',\n",
       "  'british empire',\n",
       "  'slavery',\n",
       "  'africa',\n",
       "  'atlantic slave trade',\n",
       "  'african slave trade'],\n",
       " ['14th century', 'renaissance', 'ancient greece', 'greece'],\n",
       " ['14th century',\n",
       "  'italy',\n",
       "  'roman catholic church',\n",
       "  'hiv',\n",
       "  'ronald reagan',\n",
       "  'president of the united states',\n",
       "  'john f. kennedy']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the articles list in the lists of paths\n",
    "    \n",
    "clicked_articles=[]\n",
    "for x in paths_finished['path']: # hypothesize also in paths_unfinished\n",
    "    path=(x.split(';'))\n",
    "    clicked_articles.append(path)\n",
    "\n",
    "clicked_articles_filtered=[]\n",
    "for path in clicked_articles:\n",
    "    path_filtered=filter_article_name(path)\n",
    "    if '<' in path:\n",
    "        path.remove('<') #it does not work\n",
    "    clicked_articles_filtered.append(path_filtered)\n",
    "\n",
    "clicked_articles_filtered[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fdf6dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>#_clicks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>%c3%85land</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>%c3%89douard manet</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>%c3%89ire</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>%e2%82%ac2 commemorative coins</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10th century</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             link  #_clicks\n",
       "1                      %c3%85land         2\n",
       "2              %c3%89douard manet         2\n",
       "3                       %c3%89ire         3\n",
       "5  %e2%82%ac2 commemorative coins         1\n",
       "6                    10th century       109"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the dataframe containing the hyperlinks and their clicktrhough frequency\n",
    "\n",
    "links_name=[]\n",
    "links_freq=[]\n",
    "\n",
    "i=0\n",
    "\n",
    "for article in articles['article']:\n",
    "    count=0\n",
    "    links_name.append(article)\n",
    "    for i in range(len(clicked_articles_filtered)):\n",
    "        if article in clicked_articles_filtered[i]:\n",
    "            count+=1 \n",
    "    links_freq.append(count)\n",
    "\n",
    "links_name=pd.Series(links_name)\n",
    "links_freq=pd.Series(links_freq)\n",
    "links_freq_df=pd.concat([links_name, links_freq], axis=1, names=['link', '#_clicks'])\n",
    "links_freq_df.columns=['link', '#_clicks']\n",
    "links_freq_df.loc[links_freq_df['#_clicks']!=0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "675681ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for extracting the positioning of the hyperlinks in the article text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa8883c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52aae5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all the files\n",
    "\n",
    "soups=[]\n",
    "failed_html_list = []\n",
    "for html in html_list[:]:\n",
    "    f=open(wp_path+html, 'r')\n",
    "    try:\n",
    "        soup = BeautifulSoup(f, 'lxml')\n",
    "        soups.append(soup)\n",
    "    except Exception:\n",
    "        failed_html_list.append(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a9a7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_html_list[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f461b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example with 1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad2d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = '/Users/ginevralarroux/Desktop/EPFL courses/Applied data analysis/ADA project/data/wpcd/wp/a/A_cappella.htm'\n",
    "\n",
    "f=open(URL, 'r')\n",
    "soup = BeautifulSoup(f, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0181db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML tag for hyperlinks is <a href= >\n",
    "# this is the dataframe of the hyperlinks contained in an article, with the number of paragraph they show up in \n",
    "# and its relative postion in the article\n",
    "\n",
    "paragraphs = soup.find_all('p')\n",
    "\n",
    "links=[]\n",
    "i=0\n",
    "\n",
    "for p in paragraphs:\n",
    "    i+=1\n",
    "    all_links=p.find_all('a')\n",
    "    for link in all_links:\n",
    "        if 'href' in link.attrs:\n",
    "            link_title=link.text\n",
    "            link_paragraph=i\n",
    "            links.append([link_title, link_paragraph])\n",
    "\n",
    "link_positioning_df=pd.DataFrame(links, columns=['link', '#_paragraph']).drop_duplicates()\n",
    "link_positioning_df['positioning']=round(link_positioning_df['#_paragraph']/len(paragraphs), 2)\n",
    "link_positioning_df['link']=filter_article_name(link_positioning_df['link'])\n",
    "link_positioning_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0c894c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# function for all html files\n",
    "\n",
    "def find_links(soups):\n",
    "    dfs=[]\n",
    "    for soup in soups:\n",
    "        paragraphs = soup.find_all('p')\n",
    "        \n",
    "        links=[]\n",
    "        i=0\n",
    "        for p in paragraphs:\n",
    "            i+=1\n",
    "            all_links=p.find_all('a')\n",
    "            for link in all_links:\n",
    "                if 'href' in link.attrs:\n",
    "                    link_title=link.text\n",
    "                    link_paragraph=i\n",
    "                    links.append([link_title, link_paragraph])\n",
    "\n",
    "        link_positioning_df=pd.DataFrame(links, columns=['link', '#_paragraph']).drop_duplicates()\n",
    "        link_positioning_df['positioning']=round(link_positioning_df['#_paragraph']/len(paragraphs), 2)\n",
    "        link_positioning_df['link']=filter_article_name(link_positioning_df['link'])\n",
    "        dfs.append(link_positioning_df)\n",
    "    return dfs\n",
    "\n",
    "link_positioning_dfs=find_links(soups)\n",
    "link_positioning_dfs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90749cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis of 2 files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7acfe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = '/Users/ginevralarroux/Desktop/EPFL courses/Applied data analysis/ADA project/data/wpcd/wp/m/Music.htm'\n",
    "\n",
    "f_music=open(URL, 'r')\n",
    "soup_music = BeautifulSoup(f_music, 'lxml')\n",
    "\n",
    "paragraphs_m = soup_music.find_all('p')\n",
    "\n",
    "links_m=[]\n",
    "i=0\n",
    "\n",
    "for p in paragraphs_m:\n",
    "    i+=1\n",
    "    all_links=p.find_all('a')\n",
    "    for link in all_links:\n",
    "        if 'href' in link.attrs:\n",
    "            link_title=link.text\n",
    "            link_paragraph=i\n",
    "            links_m.append([link_title, link_paragraph])\n",
    "\n",
    "link_positioning_df_m=pd.DataFrame(links_m, columns=['link', '#_paragraph']).drop_duplicates()\n",
    "link_positioning_df_m['positioning']=round(link_positioning_df_m['#_paragraph']/len(paragraphs_m), 2)\n",
    "link_positioning_df_m['link']=filter_article_name(link_positioning_df_m['link'])\n",
    "link_positioning_df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715437cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the 2 dataframes\n",
    "\n",
    "merged=link_positioning_df.merge(link_positioning_df_m, how='outer', left_on='link', right_on='link', )\n",
    "columns_to_drop=['#_paragraph_x', '#_paragraph_y']\n",
    "m=merged.drop(labels=columns_to_drop, axis=1)\n",
    "m.reset_index(drop=True, inplace=True)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fc8ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for all html files\n",
    "\n",
    "for df in link_positioning_dfs:\n",
    "    df.drop(labels='#_paragraph', axis=1, inplace=True)  \n",
    "\n",
    "link_positioning_dfs=link_positioning_dfs[:10]\n",
    "from functools import reduce\n",
    "links_pos_dfs_merged = reduce(lambda  left,right: pd.merge(left,right,on=['link'],how='outer'), link_positioning_dfs)\n",
    "links_pos_dfs_merged.head(50) #need to fix this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5edc8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that determines the msot frequent position of each hyperlink in the set of all articles\n",
    "\n",
    "def find_positioning(array):\n",
    "    bin_labels=['top', 'center', 'bottom']\n",
    "    bins=[0, 0.33, 0.66, 1]\n",
    "    cut_positioning=pd.cut(array, bins, labels=bin_labels)\n",
    "    positioning_frequency=pd.value_counts(cut_positioning)\n",
    "    most=positioning_frequency.apply('max')\n",
    "    if len(positioning_frequency[positioning_frequency==most])>1:\n",
    "        return np.random.choice(positioning_frequency[positioning_frequency==most].index.values.astype(str)) #account for same frequency\n",
    "    else:\n",
    "        return positioning_frequency[positioning_frequency==most].index.values.astype(str).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a78ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_freq_positioning=m.groupby(by=m['link']).apply(lambda x: find_positioning(np.array(x.values).flatten()))\n",
    "most_freq_positioning_df=pd.DataFrame(most_freq_positioning, columns=['most_freq_positioning'])\n",
    "most_freq_positioning_df=most_freq_positioning_df.reset_index()\n",
    "most_freq_positioning_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for all html files\n",
    "\n",
    "most_freq_positioning=links_pos_dfs_merged.groupby(by=links_pos_dfs_merged['link']).apply(lambda x: find_positioning(np.array(x.values).flatten()))\n",
    "most_freq_positioning_df=pd.DataFrame(most_freq_positioning, columns=['most_freq_positioning'])\n",
    "most_freq_positioning_df=most_freq_positioning_df.reset_index()\n",
    "most_freq_positioning_df #need to fix this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61845f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_freq_pos=links_freq_df.merge(most_freq_positioning_df, left_on='link', right_on='link')\n",
    "links_freq_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2d559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_freq_pos_grouped=links_freq_pos['#_clicks'].groupby(links_freq_pos['most_freq_positioning']).sum()\n",
    "links_freq_pos_grouped_df=pd.DataFrame(links_freq_pos_grouped)\n",
    "links_freq_pos_grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bd260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of the Distribution of the clicked hyperlinks' positioning\n",
    "\n",
    "links_freq_pos.sort_values(by='#_clicks', ascending=False, inplace=True)\n",
    "#links_freq_pos=links_freq_pos[:1000] # may be interesting to 1000 most clicked articles \n",
    "#links_freq_pos=links_freq_pos[:-1000] # 1000 least clicked articles \n",
    "\n",
    "ax = links_freq_pos_grouped_df.plot.bar()\n",
    "ax.set_title('Distribution of the clicked hyperlinks positioning')\n",
    "ax.set_xlabel('Positioning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a9fb0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc284fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5053db34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419590e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed2e5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for finding hyperlinks in images' caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d3f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example with 1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a372cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = '/Users/ginevralarroux/Desktop/EPFL courses/Applied data analysis/ADA project/data/wpcd/wp/a/Aachen.htm'\n",
    "f2=open(URL, 'r')\n",
    "soup2 = BeautifulSoup(f2, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7539e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in an HTML file the images can be either find under tables or div tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3978781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images of hyperlinks in tables' captions\n",
    "\n",
    "tables = soup2.find_all('table')\n",
    "\n",
    "links=[]\n",
    "for table in tables:\n",
    "    if table.find('img'):\n",
    "        all_links=table.find_all('a')\n",
    "        for link in all_links:\n",
    "            if 'class' not in link.attrs:\n",
    "                link_title=link.text\n",
    "                links.append(link_title)\n",
    "\n",
    "links_in_table_df=pd.DataFrame(links)\n",
    "links_in_table_df.columns=['link']\n",
    "links_in_table_df=links_in_table_df.apply(filter_article_name) \n",
    "links_in_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a9df9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# function for all html files\n",
    "\n",
    "def find_links_in_table(soups):\n",
    "    dfs=[]\n",
    "    for soup in soups:\n",
    "        tables = soup.find_all('table')\n",
    "        if(tables):\n",
    "            print(len(tables))\n",
    "            links=[]\n",
    "            for table in tables:\n",
    "                if table.find('img'):\n",
    "                    print('img')\n",
    "                    \n",
    "                    all_links=table.find_all('a')\n",
    "                    if all_links:\n",
    "                        print('links_len={0}'.format(len(all_links)))\n",
    "                        for link in all_links:\n",
    "                            #if 'class' not in link.attrs:\n",
    "                            if link.text:\n",
    "                                print('yes')\n",
    "                                link_title=link.text\n",
    "                                links.append(link_title)\n",
    "                                print(link_title)\n",
    "                            else:\n",
    "                                print('no')\n",
    "        print(links)\n",
    "        print(len(links))\n",
    "\n",
    "        #links_in_table_df=pd.DataFrame(links)\n",
    "        #links_in_table_df.columns=['link_in_table']\n",
    "        #links_in_table_df=links_in_table_df.apply(filter_article_name) \n",
    "        #dfs.append(links_in_table_df)\n",
    "    return dfs\n",
    "\n",
    "links_in_table_dfs=find_links_in_table(soups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2fa97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images under div tags\n",
    "\n",
    "div = soup2.find_all('div')\n",
    "\n",
    "links=[]\n",
    "\n",
    "for d in div:\n",
    "    if (d.find('a', class_=\"internal\")):\n",
    "        if (d.find('img', class_='thumbimage')):\n",
    "            caption=d.find('div', class_=\"thumbcaption\")\n",
    "            if (caption.find('a')):\n",
    "                all_links=caption.find_all('a')\n",
    "                for link in all_links:\n",
    "                    if 'class' not in link.attrs:\n",
    "                        link_title=link.text\n",
    "                        links.append(link_title)\n",
    "                            \n",
    "links_in_image_df=pd.DataFrame(links).drop_duplicates() \n",
    "links_in_image_df.columns=['link']\n",
    "links_in_image_df=links_in_image_df.apply(filter_article_name)   \n",
    "links_in_image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7beaa5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# function for all html files\n",
    "\n",
    "def find_links_in_div(soups):\n",
    "    dfs=[]\n",
    "    for soup in soups:\n",
    "        div = soup.find_all('div')\n",
    "        \n",
    "        links=[]\n",
    "        for d in div:\n",
    "            if (d.find('a', class_=\"internal\")):\n",
    "                if (d.find('img', class_='thumbimage')):\n",
    "                    caption=d.find('div', class_=\"thumbcaption\")\n",
    "                    if (caption.find('a')):\n",
    "                        all_links=caption.find_all('a')\n",
    "                        for link in all_links:\n",
    "                            if 'class' not in link.attrs:\n",
    "                                link_title=link.text\n",
    "                                links.append(link_title)\n",
    "\n",
    "        links_in_image_df=pd.DataFrame(links).drop_duplicates() \n",
    "        links_in_image_df.columns=['link_in_image']\n",
    "        links_in_image_df=links_in_image_df.apply(filter_article_name)     \n",
    "    return dfs\n",
    "\n",
    "links_in_image_dfs=find_links_in_div(soups)\n",
    "links_in_image_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2c908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for frequency of clicks for link in images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf01a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example with 2 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f334f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_in_image_dfs=[links_in_image_df, links_in_table_df] #not needed for dataframes of all articles\n",
    "link_in_image_concatenated=pd.concat(links_in_image_dfs, axis=0).reset_index(drop=True).drop_duplicates()\n",
    "link_in_image_concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb663eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag=[]\n",
    "links_freq_img=links_freq_df.copy()\n",
    "\n",
    "for link in links_freq_df['link']:\n",
    "    if link in list(link_in_image_concatenated['link']):\n",
    "        flag.append(1)\n",
    "    else:\n",
    "        flag.append(0)\n",
    "    \n",
    "links_freq_img['in_image']=flag\n",
    "links_freq_img[links_freq_img['in_image']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e0a4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_freq_img_grouped_df=pd.DataFrame(links_freq_img['#_clicks'].groupby(links_freq_img['in_image']).sum())\n",
    "links_freq_img_grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31058520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of img  \n",
    "\n",
    "ax = links_freq_img_grouped_df.plot.bar()\n",
    "ax.set_title('Distribution of the clicked hyperlinks in images captions')\n",
    "ax.set_xlabel('In image caption')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a846196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumptions: \n",
    "# we don't know for the hyperlinks that show up both in the article text and in the image caption, \n",
    "# which the player actually clicked \n",
    "# for the hyperlinks which show up multiple times in the article ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59738c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f383753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def links_freq_vs_pos(dfs):\n",
    "#    merged_df=dfs[0]\n",
    "#    for df in dfs:\n",
    "#        merged_df=merged_df.merge(df, how='outer', left_on='link', right_on='link')\n",
    "#    return merged_df\n",
    "#\n",
    "#link_positioning_dfs=link_positioning_dfs[:10]\n",
    "#links_freq_pos_dfs=links_freq_vs_pos(link_positioning_dfs)\n",
    "#links_freq_pos_dfs.head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
