{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff256120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c89ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "data_path='/Users/ginevralarroux/Desktop/EPFL courses/Applied data analysis/ADA project/data/'\n",
    "parent_folder_path = data_path + 'wikispeedia_paths-and-graph/'\n",
    "\n",
    "paths_finished_df=(pd.read_csv(os.path.join(parent_folder_path, 'paths_finished.tsv'), \n",
    "                               sep='\\t', skiprows=15, header=None)\n",
    "                   .rename(columns={0:\"ip\",\n",
    "                                    1:\"timestamp\",\n",
    "                                    2:\"duration\",\n",
    "                                    3:\"path\",\n",
    "                                    4:\"rating\"}))\n",
    "\n",
    "paths_unfinished_df=(pd.read_csv(os.path.join(parent_folder_path, 'paths_unfinished.tsv'), \n",
    "                               sep='\\t', skiprows=16, header=None)\n",
    "                     .rename(columns={0:\"ip\",\n",
    "                                      1:\"timestamp\",\n",
    "                                      2:\"duration\",\n",
    "                                      3:\"path\",\n",
    "                                      4:\"target\",\n",
    "                                      5:\"type\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8367b803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4604"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first read the shortest path matrix\n",
    "shortest_path_matrix = []\n",
    "\n",
    "with open(parent_folder_path +'shortest-path-distance-matrix.txt', 'r') as f:\n",
    "    # the first 17 lines (indexed from 0) is the file description \n",
    "    for line in f.readlines()[17:]:\n",
    "        shortest_path_matrix.append(line)\n",
    "        \n",
    "# the matrix now stores all shortest paths from all source articles\n",
    "len(shortest_path_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a7532dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['áedán mac gabráin', 'åland', 'édouard manet']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next, we need a list of all the article names. The order of the articles \n",
    "# is the same as the shortest_path_matrix as per the file descriptions\n",
    "\n",
    "import urllib.parse\n",
    "def str_url_format(word):\n",
    "    \"\"\"\n",
    "    Article name preprocessing.\n",
    "    \n",
    "    Apply this function any time a new dataframe is loaded.\n",
    "    \"\"\"\n",
    "    return (urllib.parse.unquote(word)\n",
    "            .replace(\"_\", \" \")\n",
    "            .strip()\n",
    "            .lower())\n",
    "\n",
    "article_names_cleaned = (pd.read_csv(data_path + 'wikispeedia_paths-and-graph/articles.tsv', \n",
    "                                     sep='\\t', \n",
    "                                     skiprows=11,\n",
    "                                     header=None)[0]\n",
    "                         .apply(str_url_format)\n",
    "                         .values\n",
    "                         .tolist()\n",
    "                        )\n",
    "\n",
    "article_names_cleaned[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c70352ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each human path, perform the following steps:\n",
    "#      1. extract the source and target article\n",
    "#      2. find the *index* in the article names list that corresponds to the source and target article\n",
    "#      3. the corresponding *index* row in the shortest path matrix corresponds to the source article. \n",
    "#         from this list of numbers, use the target article *index* to find the *shortest path length*\n",
    "\n",
    "def augment_with_shortest_path(df: pd.DataFrame, successful: bool) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    this function takes a Series and returns a DataFrame with the following columns:\n",
    "       1. path\n",
    "       2. source article\n",
    "       3. target article\n",
    "       4. shortest path length\n",
    "       \n",
    "    input:\n",
    "       df: the Pandas DataFrame containing all the human navigation paths\n",
    "       successful: a boolean indicating whether the paths were successful or not\n",
    "    \"\"\"\n",
    "    # remove all paths with back-tracks\n",
    "    df = df[~df['path'].str.contains('<')]        \n",
    "    paths, human_path_lengths, source_articles, target_articles, shortest_paths = [], [], [], [], []\n",
    "    \n",
    "    # all information required for successful paths is in the path itself\n",
    "    if successful:\n",
    "        for human_path in df['path']:\n",
    "\n",
    "            split_path = str_url_format(human_path).split(\";\")\n",
    "            \n",
    "            paths.append(\";\".join(split_path))\n",
    "            # subtract 1 because we do not count the source article\n",
    "            human_path_lengths.append(len(split_path)-1)\n",
    "\n",
    "            source = split_path[0]\n",
    "            target = split_path[-1]\n",
    "            source_articles.append(source)\n",
    "            target_articles.append(target)\n",
    "    \n",
    "    # unsuccessful paths require extraction of the target article from a separate column\n",
    "    else:\n",
    "        for human_path, target in zip(df['path'], df['target']):\n",
    "            \n",
    "            split_path = str_url_format(human_path).split(\";\")\n",
    "            \n",
    "            paths.append(\";\".join(split_path))\n",
    "            # subtract 1 because we do not count the source article\n",
    "            human_path_lengths.append(len(split_path)-1)\n",
    "            source = split_path[0]\n",
    "            source_articles.append(source)\n",
    "            target_articles.append(target)\n",
    "        \n",
    "    for source, target in zip(source_articles, target_articles):\n",
    "        source_index = article_names_cleaned.index(source)\n",
    "        # there are target articles that were not provided in the plain text files\n",
    "        try:\n",
    "            target_index = article_names_cleaned.index(target)\n",
    "        except Exception:\n",
    "            shortest_paths.append(\"N/A\")\n",
    "            continue\n",
    "            \n",
    "        # query the shortest path matrix to get the correct vector (corresponding to the source article)\n",
    "        shortest_path_vector = shortest_path_matrix[source_index]\n",
    "        # now find the target article indexed integer in the vector\n",
    "        shortest = shortest_path_vector[target_index]\n",
    "        # it's not always possible to get to the target article. Impossible navigation is denoted by \"_\"\n",
    "        if shortest == \"_\":\n",
    "            shortest_paths.append(\"Impossible\")\n",
    "        else:\n",
    "            shortest_paths.append(int(shortest))\n",
    "        \n",
    "        \n",
    "    # create the augmented DataFrame\n",
    "    out = pd.DataFrame({\n",
    "                      'path': paths,\n",
    "                      'source_article': source_articles,\n",
    "                      'target_article': target_articles,\n",
    "                      'human_path_length': human_path_lengths,\n",
    "                      'shortest_path_length': shortest_paths\n",
    "                      })\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "826eade8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>source_article</th>\n",
       "      <th>target_article</th>\n",
       "      <th>human_path_length</th>\n",
       "      <th>shortest_path_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14th century;15th century;16th century;pacific...</td>\n",
       "      <td>14th century</td>\n",
       "      <td>african slave trade</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14th century;europe;africa;atlantic slave trad...</td>\n",
       "      <td>14th century</td>\n",
       "      <td>african slave trade</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14th century;niger;nigeria;british empire;slav...</td>\n",
       "      <td>14th century</td>\n",
       "      <td>african slave trade</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path source_article  \\\n",
       "0  14th century;15th century;16th century;pacific...   14th century   \n",
       "1  14th century;europe;africa;atlantic slave trad...   14th century   \n",
       "2  14th century;niger;nigeria;british empire;slav...   14th century   \n",
       "\n",
       "        target_article  human_path_length shortest_path_length  \n",
       "0  african slave trade                  8                    3  \n",
       "1  african slave trade                  4                    3  \n",
       "2  african slave trade                  7                    3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "successful_df = augment_with_shortest_path(df=paths_finished_df, successful=True)\n",
    "# to investigate human behaviour, we remove all \"Impossible paths\" and also shortest_path_length = 0\n",
    "successful_df = successful_df[(successful_df['shortest_path_length'].apply(lambda x: x != 'Impossible' and x != 0))]\n",
    "# next, we will keep only shortest_path_lengths >= 3\n",
    "successful_df = successful_df[(successful_df['shortest_path_length'].apply(lambda x: x >= 3))]\n",
    "\n",
    "successful_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a16765b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>source_article</th>\n",
       "      <th>target_article</th>\n",
       "      <th>human_path_length</th>\n",
       "      <th>shortest_path_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>ozone;gas;plasma (physics);phase (matter);ther...</td>\n",
       "      <td>ozone</td>\n",
       "      <td>2-8-0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10039</th>\n",
       "      <td>jake gyllenhaal;mozambique;1st century;4th cen...</td>\n",
       "      <td>jake gyllenhaal</td>\n",
       "      <td>4-2-0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15522</th>\n",
       "      <td>rutherford b. hayes;american civil war;mississ...</td>\n",
       "      <td>rutherford b. hayes</td>\n",
       "      <td>2-6-0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    path       source_article  \\\n",
       "1197   ozone;gas;plasma (physics);phase (matter);ther...                ozone   \n",
       "10039  jake gyllenhaal;mozambique;1st century;4th cen...      jake gyllenhaal   \n",
       "15522  rutherford b. hayes;american civil war;mississ...  rutherford b. hayes   \n",
       "\n",
       "      target_article  human_path_length shortest_path_length  \n",
       "1197           2-8-0                  5                    4  \n",
       "10039          4-2-0                  3                    5  \n",
       "15522          2-6-0                  5                    5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsuccessful_df = augment_with_shortest_path(df=paths_unfinished_df, successful=False)\n",
    "\n",
    "# some target articles for unsuccessful paths were not provided in the plain_text folder, denoted in\n",
    "# the DataFrame as \"N/A\". Remove these\n",
    "unsuccessful_df = unsuccessful_df[(unsuccessful_df['shortest_path_length'].apply(lambda x: x != 'N/A' and x != 'Impossible'))]\n",
    "# some unsuccesful paths only contain 1 article because the user didn't click anything\n",
    "# these are less meaningful paths to analyze as we are interested in users who tried but failed\n",
    "# we will keep paths where the human clicked at least 3 articles\n",
    "unsuccessful_df = unsuccessful_df[(unsuccessful_df['shortest_path_length'].apply(lambda x: x >= 3))]\n",
    "unsuccessful_df = unsuccessful_df[(unsuccessful_df['human_path_length'].apply(lambda x: x >= 3))]\n",
    "unsuccessful_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6a205e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GINEVRA'S CODE FROM HERE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94953e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61a8c9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>most_freq_positioning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"6 villages for 2006</td>\n",
       "      <td>center-bottom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"6 villages for 2006\"</td>\n",
       "      <td>center-top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"capitalist rule\"</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"consumption\" (tuberculosis)</td>\n",
       "      <td>top</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           link most_freq_positioning\n",
       "0                           NaN                bottom\n",
       "1          \"6 villages for 2006         center-bottom\n",
       "2         \"6 villages for 2006\"            center-top\n",
       "3             \"capitalist rule\"                   top\n",
       "4  \"consumption\" (tuberculosis)                   top"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_freq_positioning_df=pd.read_csv('./most_freq_positioning_df.csv', index_col=0)\n",
    "most_freq_positioning_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21414e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(human_path):\n",
    "    '''this function determines the categorical positioning feature of each hyperlink in the human path'''\n",
    "    return [most_freq_positioning_df.loc[link].values.item() \n",
    "                         if link in most_freq_positioning_df.index \\\n",
    "                         else np.random.choice(['top', 'center-top','center','center-bottom', 'bottom'])\n",
    "                         for link in human_path] #certain hyperlinks were not classified \n",
    "\n",
    "successful_features=successful_df['path'].apply(lambda x: x.split(\";\")).apply(lambda x: find_features(x))\n",
    "successful_features=unsuccessful_df['path'].apply(lambda x: x.split(\";\")).apply(lambda x: find_features(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ec84e96",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unsuccessful_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop\u001b[39m\u001b[38;5;124m'\u001b[39m: t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter_top\u001b[39m\u001b[38;5;124m'\u001b[39m: ct, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m'\u001b[39m: c, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter_bottom\u001b[39m\u001b[38;5;124m'\u001b[39m: cb, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottom\u001b[39m\u001b[38;5;124m'\u001b[39m: b})\n\u001b[1;32m     13\u001b[0m successful_features_freq\u001b[38;5;241m=\u001b[39mfind_features_frequency(successful_features)\n\u001b[0;32m---> 14\u001b[0m unsuccessful_features_freq\u001b[38;5;241m=\u001b[39mfind_features_frequency(\u001b[43munsuccessful_features\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unsuccessful_features' is not defined"
     ]
    }
   ],
   "source": [
    "def find_features_frequency(features):\n",
    "    '''this function counts the frequency of the categorical positioning features of the hyperlinks in each human path'''\n",
    "    t, ct, c, cb, b=[], [], [], [], []\n",
    "\n",
    "    for path in features:\n",
    "        t.append(path.count('top'))\n",
    "        ct.append(path.count('center-top'))\n",
    "        c.append(path.count('center'))\n",
    "        cb.append(path.count('center-bottom'))\n",
    "        b.append(path.count('bottom'))\n",
    "    return pd.DataFrame({'top': t, 'center_top': ct, 'center': c, 'center_bottom': cb, 'bottom': b})\n",
    "\n",
    "successful_features_freq=find_features_frequency(successful_features)\n",
    "unsuccessful_features_freq=find_features_frequency(unsuccessful_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a163e2d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unsuccessful_features_freq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_std\n\u001b[1;32m      9\u001b[0m successful_features_std\u001b[38;5;241m=\u001b[39mstandardize_features(successful_features_freq)\n\u001b[0;32m---> 10\u001b[0m unsuccessful_features_std\u001b[38;5;241m=\u001b[39mstandardize_features(\u001b[43munsuccessful_features_freq\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unsuccessful_features_freq' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#standardize features \n",
    "\n",
    "def standardize_features(df):\n",
    "    df_std=pd.DataFrame()\n",
    "    for c in df.columns:\n",
    "        df_std[c]=(df[c]-df[c].mean())/df[c].std()\n",
    "    return df_std\n",
    "\n",
    "successful_features_std=standardize_features(successful_features_freq)\n",
    "unsuccessful_features_std=standardize_features(unsuccessful_features_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b962547e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bangladesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>portsmouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>england</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pompeii</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         link\n",
       "0  bangladesh\n",
       "1  portsmouth\n",
       "2     england\n",
       "3       india\n",
       "4     pompeii"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_in_images_unique=pd.read_csv('./links_in_images_unique.csv', index_col=0)\n",
    "links_in_images_unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87217c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_img_features=successful_df['path'].apply(lambda x: x.split(\";\")).apply(lambda x: np.isin(x, links_in_images_unique).sum() \\\n",
    "                                                          if np.isin(x, links_in_images_unique).sum() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e787be",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(successful_img_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6c3c60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
